<!DOCTYPE html>
<html lang="en" dir="ltr" typeof="bibo:Document " prefix="bibo: http://purl.org/ontology/bibo/ w3p: http://www.w3.org/2001/02pd/rec54#">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta lang="" property="dc:language" content="en">
  <meta content="width=device-width,initial-scale=1" name="viewport">
  <title>Spatial Data on the Web Use Cases &amp; Requirements</title>
  <script src='http://www.w3.org/Tools/respec/respec-w3c-common' async class='remove'></script>
  <style type="text/css">
  .contributor:before {
    content: "Contributed by: ";
    font-weight: bold;
  }
  .relatedDeliverables:before {
    content: "Related deliverables: ";
    font-weight: bold;
  }
  .relatedRequirements:before {
    content: "Related requirements: ";
    font-weight: bold;
  }
  .relatedUseCases:before {
    content: "Related use cases: ";
    font-weight: bold;
  }
  .expand{
    display:block;
  }
  .expand:before {
    font-weight: bold;
    content: "\25BA Full use case description (click to expand or collapse):";
  }
  .expand + input{
    display:none;
  }
  .expand + input + *{
    display:none;
  }
  .expand + input:checked + *{
    display:block;
  }
  </style> 
  <script class='remove'>
    var respecConfig = {
      specStatus: "ED",
      shortName: "sdw-ucr",
      //publishDate:  "2015-02-12",
      //previousPublishDate: "2014-03-27",
      //previousMaturity: "FPWD",
      //previousURI: "http://www.w3.org/TR/2014/WD-tabular-data-model-20140327/",
      edDraftURI: "http://w3c.github.io/sdw/UseCases/SDWUseCasesAndRequirements.html",
      // lcEnd: "3000-01-01",
      // crEnd: "3000-01-01",
      editors: [
      {
        name: "Frans Knibbe",
        company: "Geodan",
        companyURL: "http://www.geodan.nl/"
      },
      {
        name: "Alejandro Llaves",
        company: "Universidad Politécnica de Madrid",
        companyURL: "http://www.upm.es/"
      }],
      wg: "Spatial Data on the Web Working Group",
      wgURI: "http://www.w3.org/2015/spatial/",
      wgPublicList: "public-sdw-wg",
      wgPatentURI: "http://www.w3.org/2004/01/pp-impl/68239/status",
      inlineCSS: true,
      noIDLIn: true,
      noLegacyStyle: false,
      logos: [
      {
        src: "http://www.w3.org/Icons/w3c_home",
        alt: "W3C",
        height: "48",
        width: "72",
        url: "http://www.w3.org/"
      },
      {
        src: "http://www.w3.org/2015/01/ogc_logo.jpg",
        alt: "OGC",
        height: "48",
        width: "115",
        url: "http://www.opengeospatial.org/"
      }
      ],
      noRecTrack: true,
      overrideCopyright: "<p class='copyright'><a href='http://www.w3.org/Consortium/Legal/ipr-notice#Copyright'>Copyright</a> © 2015 <a href='http://www.opengeospatial.org/'>OGC</a> &amp; <a href='http://www.w3.org/'> <abbr title='World Wide Web Consortium'>W3C</abbr> </a><sup>®</sup> (<a href='http://www.csail.mit.edu/'><abbr title='Massachusetts Institute of Technology'>MIT</abbr></a>, <a href='http://www.ercim.eu/'><abbr title='European Research Consortium for Informatics and Mathematics'>ERCIM</abbr></a>, <a href='http://www.keio.ac.jp/'>Keio</a>, <a href='http://ev.buaa.edu.cn/'>Beihang</a>), <abbr title='World Wide Web Consortium'>W3C</abbr> <a href='http://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer'>liability</a>, <a href='http://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks'>trademark</a> and <a href='http://www.w3.org/Consortium/Legal/copyright-documents'>document use</a> rules apply.</p>"
    };
  </script>
  <body>
    <section id='abstract'>
      <p>
        This document is the first deliverable of the <a href="http://www.w3.org/2015/spatial/">Spatial Data on the Web Working Group</a>. It describes uses cases and requirements for further work that are derived from the use cases.
      </p>
    </section>
    <section id='sotd'>
    </section>
    <section>
      <h2>Introduction</h2>
      <p>
        The mission of the <a href="http://www.w3.org/2015/spatial/">Spatial Data on the Web Working Group</a>, as described in the <a href="http://www.w3.org/2015/spatial/charter">charter</a>, is to clarify and to formalize standards on spatial data on the web. In particular:
        <ol>
        <li>to determine how spatial information can best be integrated with other data on the Web;</li>
        <li>to determine how machines and people can discover that different facts in different datasets relate to the same place, especially when 'place' is expressed in different ways and at different levels of granularity;</li>
        <li>to identify and assess existing methods and tools and then create a set of best practices for their use;</li>
        <li>where desirable, to complete the standardization of informal technologies already in widespread use.</li>
        </ol>
        This document describes the results of the first steps of working towards these goals. Members of the working group and other stakeholders have come up with a number of <a href="#UseCases">use cases</a> that describe how spatial data on the web could work. From these use cases, a number of <a href="#Requirements">requirements</a> for further work are derived. In this document, use cases, requirements and their relationships are described. Requirements and use cases are also related to the <a href="#Deliverables">deliverables</a> of the working group.      
      </p>
      <p>
        The requirements described in this document will be the basis for development of the other four deliverables of the Working Group.
      </p>
    </section>
    <section id="Deliverables">
      <h2>Deliverables</h2>
      <p>
      The deliverables of this Working Group are described in the <a href="http://www.w3.org/2015/spatial/charter">Working Group Charter</a>. For convenience, and to have URIs, those deliverables are replicated in this chapter. The charter remains the authorative source of the definition of deliverables.
      </p>
      <section id="UseCasesAndRequirements">
        <h3>Use Cases and Requirements</h3>
        <p>A document setting out the range of problems that the working groups are trying to solve (this document).</p>
      </section>
      <section id="BestPractices">
        <h3>Spatial Data on the Web Best Practices</h3>
        <p>This will include:
        <ul>
        <li>an agreed spatial ontology conformant to the ISO 19107 abstract model and based on existing available ontologies such as GeoSPARQL, NeoGeo and the ISA Core Location vocabulary;</li>
        <li>advice on use of URIs as identifiers in GI systems;</li>
        <li>advice on providing different levels of metadata for different usage scenarios (from broad sweep metadata to metadata about individual coordinates in a polygon);</li>
        <li>develop advice on, or possibly define, RESTful APIs to return data in a variety of formats including those defined elsewhere, such as GeoJSON, GeoJSON-LD and TopoJSON.</li>
        </ul>
        </p>
      </section>
      <section id="TimeOntologyInOWL">
        <h3>Time Ontology in OWL</h3>
        <p>The WG will work with the authors of the existing Time Ontology in OWL to complete the development of this widely used ontology through to Recommendation status. Further requirements already identified in the geospatial community will be taken into account.</p>
      </section>
      <section id="SemanticSensorNetworkVocabulary">
        <h3>Semantic Sensor Network Vocabulary</h3>
        <p>The WG will work with the members of the former Semantic Sensor Network Incubator Group to develop its ontology into a formal Recommendation, noting the work to split the ontology into smaller sections to offer simplified access.</p>
      </section>
      <section id="CoverageInLinkedData">
        <h3>Coverage in Linked Data</h3>
        <p>The WG will develop a formal Recommendation for expressing discrete coverage data conformant to the ISO 19123 abstract model. Existing standard and de facto ontologies will be examined for applicability; these will include the RDF Data Cube. The Recommendation will include provision for describing the subset of coverages that are simple timeseries datasets - where a time-varying property is measured at a fixed location. OGC's WaterML 2 Part 1 - Timeseries will be used as an initial basis.</p>
        <p>Given that coverage data can often be extremely large in size, publication of the individual data points as Linked Data may not always be appropriate. The Recommendation will include provision for describing an entire coverage dataset and subsets thereof published in more compact formats using Linked Data. For example where a third party wishes to annotate a subset of a large coverage dataset or a data provider wishes to publish a large coverage dataset in smaller subsets to support convenient reuse.</p>
      </section>
    </section>
    <section id="Methodology">
      <h2>Methodology</h2>
      <p>The Working Group has derived requirements from the collected use cases. Care was taken to only derive requirements that are considered to in scope for the further work of the Working Group. To aid in this process, the following scoping questions were applied:
      <ol>
      <li>Is the use case specifically about Spatial data on the Web?</li>
      <li>Is the use case including data published, reused, and accessible via Web technologies?</li>
      <li>Has a use case a description that can lead to a testable requirement?</li>
      </ol>
      </p>
    </section>
    <section id="UseCases">
      <!--A HTML template for use cases can be found at the end of this section -->
      <h2>Use Cases</h2>
        <p>Use cases that describe current problems or future opportunities for spatial data on the web have been gathered as a first activity of the Working Group. They were mainly contributed by members of Working Group, but there were also contributions from other interested parties. In this chapter the use cases are listed and identified. Each use case is related to one or more Working Group <a href="#Deliverables">deliverables</a>. The use cases were analyzed by the Working Group, which led to a set of <a href="#Requirements">requirements</a> for future deliverables. For each use case related requirements are also listed.</p>
        <section id="MeteorologicalDataRescue">
          <h3>Meteorological Data Rescue</h3>
          <p class="contributor">Chris Little, based on scenarios used for the WMO insfrastructure requirements.</p>
          <label class="expand" for="uc1"></label>
          <input id="uc1" type="checkbox">
          <div>
          <p>This is really one of several future, but realistic, meteorological scenarios to aim at.</p>
          <p>National Hydro-Meteorological Services around the world are coordinated via the WMO (World Meteorological Organisation), part of the the United Nations system. WMO has the same status as ISO, and its standards and regulatory materials applies to all its 193 national meteorological services and are available in the six working languages ( عربي | 中文 | Fr | Ru | Es | En). WMO has embarked on a long-term (think a decade or so) programme to update the global meteorological operational infrastructure. This is known as the WIS (WMO Information System). The global infrastructure also has aviation, oceanographic, seismic and other users. The WIS includes a global, federated, synchronized, geospatial catalogue, envisaged to encompass all hydro-meteorological data and services. Currently several nodes are operational, cataloguing mainly routinely exchanged observations and forecasts.</p>
          <p>Envisage an environmental scientist in Cambodia, researching the impact of deforestation in Vietnam as part of investigating the regional impacts of climate change. She submits her search keywords, in Cambodian, and receives responses indicating there is some data from the 1950s, printed in a 1960 pamphlet, in the Bibliothèque Nationale, a library in Paris, France, in French. She receives an abstract of some form that enables her to decide that the data are worth accessing, and initiates a request for a digital copy to be sent.</p>
          <p>She receives the pamphlet as a scanned image of each page, and she decides that the quantatitive information in the paper is useful, so she arranges transcription of the tabular numerical data and their summary values into a digital form and publishes the dataset, with a persistent identifier, and links it to a detailed coverage extent, the original paper source, the scanned pages and her paper when it is published. She also incorporates scanned charts and graphs from the orginal pamphlet into her paper.Her organisation creates a catalogue record for her research paper dataset and publishes it in the WIS global catalogue, which makes it also visible to the GEO System of Systems broker portal.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SemanticSensorNetworkVocabulary"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#Discoverability"></a></p>
        </section>
        <section id="HabitatZoneVerification">
          <h3>Habitat zone verification for designation of Marine Conservation Zones</h3>
          <p class="contributor">Jeremy Tandy</p>
          <label class="expand" for="uc2"></label>
          <input id="uc2" type="checkbox">
          <div>
            <p>The <a href="http://jncc.defra.gov.uk/page-5230">Marine and Coastal Access Act 2009</a> allows for the creation of a type of Marine Protected Area (MPA), called a Marine Conservation Zone (MCZ). MCZs protect a range of nationally important marine wildlife, habitats, geology and geomorphology and can be designated anywhere in English and Welsh inshore and UK offshore waters.</p>
            <p>The designation of a MCZ is dependent on a detailed analysis of the marine environment which results in the definition of geometric areas where a given habitat type is deemed to occur and is published as a habitat map.</p>
            <p>Being a policy statement, it is important to be able to express the provenance of information that was used to compile the habitat map. Moreover, because the marine environment is always changing, it is important to express the time at which this information was collected.</p>
            <p>The information includes:
            <ul>
              <li>acoustic survey</li>
              <li>video (from a video camera towed behind a boat)</li>
              <li>biota observations (based on what is observed in the video and physical collection)</li>
              <li>particle size (sand/mud)</li>
              <li>water column data</li>
              <li>seabed character map: discrete seabed features & backscatter information (from sonar) to determine bottom type</li>
            </ul>
            These information types are varied in type and size. In particular, the acoustic survey (e.g. side-scan sonar) is difficult to manage as these survey results can be many gigabytes in size and cover large areas. A way is needed to refer to just a small part of these coverage data sets that are relevant to a particular habitat zone analysis.
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SemanticSensorNetworkVocabulary"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="RealtimeWildfireMonitoring">
          <h3>Real-time Wildfire Monitoring</h3>
          <p class="contributor">Manolis Koubarakis</p>
          <label class="expand" for="uc3"></label>
          <input id="uc3" type="checkbox">
          <div>
            <p>This use case is about the wildfire monitoring service of the National Observatory of Athens (NOA) as studied in project <a href ="http://www.earthobservatory.eu/">TELEIOS</a>.The wildfire monitoring service is based on the use of satellite images originating from the SEVIRI (Spinning Enhanced Visible and Infrared Imager) sensor on top of the Meteosat Second Generation satellites MSG-1 and MSG-2. Since 2007, NOA operates an MSG/SEVIRI acquisition station, and has been systematically archiving raw satellite images on a 5 and 15 minutes basis, the respective temporal resolutions of MSG-1 and MSG-2.</p>
            <p>The service active in NOA before TELEIOS can be summarized as follows:
            <ol>
              <li> The ground-based receiving antenna collects all spectral bands from MSG-1 and MSG-2 every 5 and 15 minutes respectively.</li>
              <li>The raw datasets are decoded and temporarily stored in the METEOSAT Ground Station as wavelet compressed images.</li>
              <li>A Python program manages the data stream in real-time by offering the following functionality:
              <ol>
                <li>Extract and store the raw file metadata in an SQLite database. This metadata describes the type of sensor, the acquisition time, the spectral bands captured, and other related parameters. Such a step is required as one image comprises multiple raw files, which might arrive out-of-order.</li>
                <li>Filter the raw data files, disregarding non-applicable data for the fire monitoring scenario, and dispatch them to a dedicated disk array for permanent storage.</li>
                <li>Trigger the processing chain by transferring the appropriate spectral bands via FTP to a dedicated machine and initiating the following steps: (i) cropping the image to keep only the area of interest, (ii) georeferencing to the geodetic reference system used in Greece (HGRS 87), (iii) classifying the image pixels as "fire" or "non-fire" using appropriate algorithms, and finally (iv) exporting the final product to raster and vector formats (ESRI shapefiles).</li>
                <li>Dispatch the derived products to the disk array and additionally store them in a PostGIS database system.</li>
              </ol></li>
            </ol>
            It would be interesting for NOA to see how to use the standards developed by this working group to achieve the following:
            <ul>
            <li>Improve the thematic accuracy of generated products.</li>
            <li>Generate thematic maps by combining the generated products with other kinds of data such as: Corine Land Cover, the Administrative Geography of Greece, OpenStreetMap data and Geonames.</li>
            </ul>
            This use case is further discussed in <a href="http://cgi.di.uoa.gr/~koubarak/publications/edbt2013.pdf">this paper</a>.<br>
            The service is operational <a href = "http://ocean.space.noa.gr/seviri_u/fend_new/index.php">here</a>.<br>
            Some data that can be used by the service can be found <a href="http://linkedopendata.gr/">here</a>.
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SemanticSensorNetworkVocabulary"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="DiachronicBurntScarMapping">
          <h3>Diachronic Burnt Scar Mapping</h3>
          <p class="contributor">Manolis Koubarakis</p>
          <label class="expand" for="uc4"></label>
          <input id="uc4" type="checkbox">
          <div>
          <p>This use case was studied by the National Observatory of Athens (NOA) in project <a href ="http://www.earthobservatory.eu/">TELEIOS</a>. The burnt scar mapping service is dedicated to the accurate mapping of burnt areas in Greece after the end of the summer fire seasons, using Landsat 5 TM satellite images. The processing chain of this service is divided into three stages, each one containing a series of modules.</p>
          <p>The pre-processing stage is dedicated to (i) identification of appropriate data, downloading and archiving, (ii) georeferencing of the received satellite images, and (iii) cloud masking process to exclude pixels “contaminated” by clouds from the subsequent processing steps.</p>
          <p>The core processing stage comprises (i) a classification algorithm which identifies burnt and non-burnt sets of pixels, (ii) a noise removal process that is necessary to eliminate isolated pixels that have been classified wrongfully as burnt, and (ii) converting the raster intermediate product to vector format.</p>
          <p>Finally, the post-processing stage consists of (i) a visual refinement step to ensure product thematic accuracy and consistency, (ii) attribute enrichment of the product by overlaying the polygons with geoinformation layers and finally (iii) generation of thematic maps.It would be interesting for NOA to see where the standards to be developed in this working group could be used.</p>
          <p>The service is operational <a href="http://ocean.space.noa.gr/seviri_u/fend_new/index.php">here</a>.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SemanticSensorNetworkVocabulary"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="HarvestingLocalSearchContent">
          <h3>Harvesting of Local Search Content</h3>
          <p class="contributor">Ed Parsons</p>
          <label class="expand" for="uc5"></label>
          <input id="uc5" type="checkbox">
          <div>
          <p>This is a rather generic and broad use case, relevant to Google but clearly also relevant to anyone interesting in machine processing of html referring to about locations and activities which take place at those locations. Local search providers spend much time and effort creating databases of local facilities, businesses and events.</p>
          <p>Much of this information comes from web pages published on the public web, but in an unstructured form. Previous attempts at harvesting this information automatically have meet with only limited success, currently alternative approaches involve business owners manually adding structured data to dedicated portals. This approach although clearly an improvement does not really scale and there are clearly issues in terms of data sharing and freshness.</p>
          <p>The information of interest includes:
          <ul>
          <li>The facilities address</li>
          <li>The type of business/activity</li>
          <li>Opening hours</li>
          <li>Date, time and duration duration of events</li>
          <li>Telephone, e-mail and website details</li>
          </ul>
          </p>
          <p>Complexities to this include multiple address standards, the differences between qualitative representations of place, and precise spatial co-ordinates, definitions of activities etc.</p>
          <p>Ultimately these web pages should become the canonical source of local data used by all web users and services.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="LocatingAThing">
          <h3>Locating a thing</h3>
          <p class="contributor">Ed Parsons</p>
          <label class="expand" for="uc6"></label>
          <input id="uc6" type="checkbox">
          <div>
          <p>With the increasing availability of small, mobile location aware devices the requirement to identify a location human terms is becoming more important. While the determination of sensor in space to a high level of precision is a largely solved problem we are less able to express the location in terms meaningful to humans. The fact that the Bluetooth-LE tracker attached to my bag is at 51.4256853,-0.3317991,4.234500 is much less useful than the description, "Under your bed at home". At others times the location descriptions "24 Bridgeman Road, Teddington, TW11 8AH, UK" might be equally valid, as might "Teddington", "South West London", "England", "UK", "Inside", "Where you left it Yesterday", "Upstairs", "45 minutes from here" or "150 metres from the Post Office".</p>
          <p>A better understanding of how we describe places in human terms, the hierarchical nature of places and the fuzzy nature of many geographical entities will be needed to make the "Internet of Things" manageable. A new scale of geospatial analysis may be required using a reference frame based on the locations of individuals rather than a global spherical co-ordinate, allowing a location of your keys and their attached bluetooth tag to be described as "in the kitchen".</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="PublishingGeographicalData">
          <h3>Publishing geographical data</h3>
          <p class="contributor">Frans Knibbe</p>
          <label class="expand" for="uc7"></label>
          <input id="uc7" type="checkbox">
          <div>
            <p>This use case is for representing the perspective of a party that is interested in publishing data on the web and wants to do it right with respect to the geographical component of the data. The point of this use case is that it would be good to remove barriers that stand in the way of more spatial data becoming available on the web.</p>
            <p>A data publisher could have the following questions:
            <ol>
              <li>How should I publish vector data? What is the best encoding to use?</li>
              <li>How should I publish raster data?</li>
              <li>How do I make the CRS known?</li>
              <li>How do I make the spatial resolution/level of detail/accuracy known?</li>
              <li>Which data publishing software has good support of geographical data types and geographical functions?</li>
              <li>Which data publishing software has good performance when it comes to spatial operations on data?</li>
            </ol>
  From the last two questions it follows that the WG could also be involved in enabling conformance testing and stimulating development of benchmarks for software.
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="ConsumingGeographicalDataInAWebApplication">
          <h3>Consuming geographical data in a web application</h3>
          <p class="contributor">Frans Knibbe</p>
          <label class="expand" for="uc8"></label>
          <input id="uc8" type="checkbox">
          <div>
          <p>This use case is somewhat complementary to use case <a href="">PublishingGeographicalData</a>. It takes the consumer perspective, specifically that of a developer of a web application that should visualise data and allow some kind of user interaction. The hypothetical web application has little or no prior knowledge about the data it will encounter on the web, but should be able to do something meaningful with any spatial data that are encountered, like drawing data on a map or rendering the data in a 3D city scape.</p>
          <p>The point of this use case is that in order for spatial data on the web to be succesful, supply and demand must be balanced to create a positive feedback loop. High quality data must be available in high quantitities but those data must also be highly usable for experts as well as non-experts.</p>
          <p>A web application developer could have the following questions:
          <ol>
            <li>How do I find geographical data on the web?</li>
            <li>How can I tell what kind of spatial data I will get? Raster or vector? 2D or 3D?<li>
            <li>Which encoding of vector data can I expect?</li>
            <li>Which encoding of raster data can I expect?</li>
            <li>Can I get the data with coordinates that match the coordinate system of my map?</li>
            <li>What is the spatial extent of this dataset/collection of resources/resource?</li>
            <li>How can I filter data to get the most appropriate spatial representation of a resource/collection of resources?</li>
            <li>How can I use spatial data on the web without having to take a four year academic course first?</li>
            <li>Which spatial operations does this SPARQL endpoint support?</li>
            <li>Can I use spatial operations in federated queries?</li>
            <li>How can I ensure responsiveness of my application (low wait times when accessing data)?</li></p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities">
          <h3>Enabling publication, discovery and analysis of spatiotemporal data in the humanities</h3>
          <p class="contributor">Frans Knibbe, Karl Grossner</p>
          <label class="expand" for="uc9"></label>
          <input id="uc9" type="checkbox">
          <div>
          <p>Note this use case shares characteristics with <a href="PublishingCulturalHeritageData"></a>.</p>
          <p>
          A research endeavour that has just started tries to stimulate researchers in the various fields of the humanities to make research data available in such a way that the data are and remain usable by other researchers, in such a way that the data may be used for purposes other than those envisaged by the original researcher. The emphasis lies on spatiotemporal data, because they are nice to visualise (a map with a time slider) and because it is thought that it would be interesting to try to discover patterns in time and/or space in interlinked distributed data sets.</p>
          <p>This project has the following aspects that seem relevant to this Working Group:</p>
          <ol>
          <li>Technologies must be easy to implement for people that generally do not have a high affinity with IT. This goes for data publishing as well as data consumption.</li>
          <li>References to time and space are often inexact or have shifting frames of reference, so simple encodings like basic geo or ISO 8601 do not suffice.</li>
          <li>References to time and space do need to be as exact as possible, to enable automatic discovery of spatiotemporal patterns.</li>
          <li>Datasets do not just need to be published, they need to be easily discovered too, using spatial and/or temporal filters.</li>
          </ol>
          </p>
          <p>Adding examples below relevant to items 2 and 3 above, from one existing scholarly web application case, which may contribute to a more general (i.e. not necessarily historical) requirement for representing several types of uncertainty: imprecision, probability, confidence. Standards for gazetteers -particularly historical (temporal) ones- are non-existent, although several projects with potentially global reach are underway. It will be helpful to have this Working Group in dialog with developers for such projects as <a href="http://pelagios-project.blogspot.com/p/about-pelagios.html">Pelagios</a>, <a href="http://loc.gazetteer.us/">Library of Congress</a>, <a href="http://pleiades.stoa.org/">Pleiades</a>, and Past Place (cf. <a href="http://www.port.ac.uk/department-of-geography/staff/humphrey-southall.html">Humphrey Southall</a>).
          <h4>Spatial</h4>
          <ul>
            <li>A set of life path data were developed for a kinship network of 30,000 individual Britons linked by birth and marriage. Spatial data for the locations of life events has several levels of granularity, from street address (10 Downing Street) to country (China). How can spatial containment relationships for places be expressed so that spatial-temporal contemporaneity be calculated?</li>
            <li>References to places in historical works are often limited to toponyms (i.e. absent geometry or precise spatial relations), and qualified by such terms as "near," and "north of." How can these be indexed spatially so as to be discoverable?</li>
          </ul>
          <h4>Temporal</h4>
          <ul>
            <li>As with spatial data, historical sources contain temporal references at varying granularity. A single data set may contain expressions for exact dates, months, or years -- or ranges containing a mix of any of those.</li>
            <li>Temporal references are frequently inexact, or relational with variable precision. The above referenced data set has a mix, including "around March 1832," "before 1750," "after WW II."</li>
          </ul>
          </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="PublishingGeospatialReferenceData">
          <h3>Publishing geospatial reference data</h3>
          <p class="contributor">Clemens Portele</p>
          <label class="expand" for="uc10"></label>
          <input id="uc10" type="checkbox">
          <div>
          <p><i>This use is based on the <a href="http://www.elfproject.eu/documentation">European Location Framework (ELF)</a></i></p>
          <p>          Mapping and cadastral authorities maintain datasets that provide geospatial reference data. Reference data is data that a user/developer uses to provide location for her own data (by linking to it), by providing context information about a location (overlaying his data over a background map), etc.</p>
          <p>A key part of this is persistent identifiers for the published data to allow linking to the reference data. Let's assume that http URIs following the <a href="http://www.w3.org/TR/cooluris/">Cool URI note</a> are used as identifiers.</p>
          <p>In ELF - and INSPIRE - reference data is typically published using a web service by the national authority. In ELF this is an OGC Web Feature Service. To provide access to the different datasets via a single entry point, all the national services are made available via a proxy web service that also handles authentication etc. In addition, it is foreseen to publish the reference data in other commonly used web-based platforms for geospatial data to simplify the use of the data - developers and users can use the tools and APIs they are familiar with.</p>
          <p>As a result, the same administrative unit (to pick an example) is basically available via multiple (document) URIs: via the national web service, the ELF proxy web service and web services of the other platforms. Different services will support different representations (GML, JSON, etc). The web services may not be accessible by everyone and different users will have access to different document URIs.</p>
          <p>Which real-world object and document URIs for the administrative unit should be maintained and what does a GET return in order <ul>
          <li>to support linking other data to the administrative unit,</li>
          <li>to deliver the document and representation that the user expects when dereferencing the link?</li>
          </ul>
          A related challenge is that today such links are often implicit. For example, a postal code or a statistical unit code is a property in the other data, but the link is not explicit like a http URI. What is a good practice to make use of such implicit links? Should they be converted to http URIs to be explicit or are there better ways (e.g. additional context that provide information about the semantics and a pattern how to construct dereferencable URIs)?
          </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="IntegrationOfGovernmentalAndUtilityDataToEnableSmartGrids">
          <h3>Integration of governmental and utility data to enable smart grids</h3>
          <p class="contributor">Frans Knibbe</p>
          <label class="expand" for="uc11"></label>
          <input id="uc11" type="checkbox">
          <div>
          <p>The research project <a href="http://www.cerise-project.nl/index.php?lang=en">CERISE-SG</a> aims to integrate data from different domains: government, energy utilities and geography, in order to enable establishment of smart energy grids.</p>
          <p>The project has recognized Linked Data as an appropriate concept for integration of data from separate semantic domains. One approach of achieving cross-domain interoperability is to switch from domain-specific semantics to common semantics. For example, the concept of an address has its own definitions in governmental standards and utility standards. Using a common definition improves interoperability.</p><p>An example of a domain model that is an international standard in electric utilities is the <a href="http://en.wikipedia.org/wiki/Common_Information_Model_(electricity)">Common Information Model (CIM)</a>. Its data model provides definitions for an important entity: the electricity meter. These meters provide useful data on consumption and production of energy. If it is possible to view these devices as sensors, it could be possible to move from domain specific semantics (CIM) to common semantics (SSN), and to have ready linkage to geographical semantics (location and network topology). What is required in this case is a low-threshold way of using sensor semantics, because people involved in integration of data from multiple domains should not be burdened with having to grasp the full complexity of each domain.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SemanticSensorNetworkVocabulary"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="UsingSpatialDataFromTheWebInGISSystemsDuringEmergencyResponseOperations">
          <h3>Using spatial data from the web in GIS systems during emergency response operations</h3>
          <p class="contributor">Bart van Leeuwen</p>
          <label class="expand" for="uc12"></label>
          <input id="uc12" type="checkbox">
          <div>
          <p>During Emergency response operations the only spatial data available to emergency response services is the predefined data in their GIS warehouses. This while the incidents and accidents handled by emergency response services are by nature unpredictable, it is impossible to determine on forehand which data you might need. Ad-hoc data available on the web with a spatial component is not easily used right now, neither can the available data about a incident be easely shared over the web.</p>
          <p>A related issue is that the relation between the data in the GIS warehouses is only spatial, while most of the time there is an <a href="DutchBaseRegistry">adminstrative relation</a> as well.</p>
          <p>Under the umbrella of various projects a first attempt has been made to at least share definitions of the terminology used by various emergency response services, both national and cross border. This resulted in the start of a project called the <a href="http://www.firebrary.com/">Firebrary</a>, now the terminology and definitions are available on the web as linked data as SKOS. Still linking from the spatial data to these definitions and vice versa is not standardized.</p>
          <p>What seems to be missing is a way to define a relationship between GIS data (in e.g. WFS services) and data on the web and vice versa, express that a certain linked data resource is also available through a GIS service (rdfs:seeAlso is too limited imho) or describe the spatial component in the linked data directly.</p>
          <p>Being able to plot and exchange data about active incidents through the web and visualize them in GIS tools with open standards would be a huge leap foreward for Emergency response services.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <!-- TO DO: link related use cases -->
        <!-- Template for use cases
        <section id="">
          <h3></h3>
          <p class="contributor"></p>
          <label class="expand" for="ucX"></label>
          <input id="ucX" type="checkbox">
          <div>
          <p></p>
          </div>
          <p class="relatedDeliverables"></p>
          <p class="relatedRequirements"></p>
        </section>
        -->
    </section>
    <section>
      <!-- A template for additional requirements can be found at the end of this section -->
      <h2>Requirements</h2>
      <p>This chapter lists the requirements for the deliverables of the Working Group.</p>

      <section id="Discoverability">
        <h3>Discoverability</h3>
        <p>It should be easy to find spatial data on the web.</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#MeteorologicalDataRescue"></a></p>
      </section>
      <section id="SpatialMetadata">
        <h3>Spatial metadata</h3>
        <p>There should be standards that allow data sources (data sets or data services) to describe their spatial characteristics (like number of dimensions, data type (raster or vector), CRSs, spatial extent, spatial resolution)</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"></a></p>
      </section>
      <!-- Template for requirments:
       <section id="Discoverability">
        <h3></h3>
        <p>I</p>
        <p class="relatedDeliverables"></a></p>
        <p class="relatedUseCases"></a></p>
      </section>
      -->
    </section>
  </body>

