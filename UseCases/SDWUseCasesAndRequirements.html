<!DOCTYPE html>
<html lang="en" dir="ltr" typeof="bibo:Document " prefix="bibo: http://purl.org/ontology/bibo/ w3p: http://www.w3.org/2001/02pd/rec54#">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta lang="" property="dc:language" content="en">
  <meta content="width=device-width,initial-scale=1" name="viewport">
  <title>Spatial Data on the Web Use Cases &amp; Requirements</title>
  <script src='http://www.w3.org/Tools/respec/respec-w3c-common' async class='remove'></script>
  <style type="text/css">
  .contributor:before {
    content: "Contributed by: ";
    font-weight: bold;
  }
  .relatedDeliverables:before {
    content: "Related deliverables: ";
    font-weight: bold;
  }
  .relatedRequirements:before {
    content: "Related requirements: ";
    font-weight: bold;
  }
  .relatedUseCases:before {
    content: "Related use cases: ";
    font-weight: bold;
  }
  .expand{
    display:block;
  }
  .expand:before {
    font-weight: bold;
    content: "\25BA Full use case description (click to expand or collapse):";
  }
  .expand + input{
    display:none;
  }
  .expand + input + *{
    display:none;
  }
  .expand + input:checked + *{
    display:block;
  }
  </style> 
  <script class='remove'>
    var respecConfig = {
      specStatus: "ED",
      shortName: "sdw-ucr",
      //publishDate:  "2015-02-12",
      //previousPublishDate: "2014-03-27",
      //previousMaturity: "FPWD",
      //previousURI: "http://www.w3.org/TR/2014/WD-tabular-data-model-20140327/",
      edDraftURI: "http://w3c.github.io/sdw/UseCases/SDWUseCasesAndRequirements.html",
      // lcEnd: "3000-01-01",
      // crEnd: "3000-01-01",
      editors: [
      {
        name: "Frans Knibbe",
        company: "Geodan",
        companyURL: "http://www.geodan.nl/"
      },
      {
        name: "Alejandro Llaves",
        company: "OEG, Universidad Politécnica de Madrid",
        companyURL: "http://www.oeg-upm.net/"
      }],
      wg: "Spatial Data on the Web Working Group",
      wgURI: "http://www.w3.org/2015/spatial/",
      wgPublicList: "public-sdw-wg",
      wgPatentURI: "http://www.w3.org/2004/01/pp-impl/68239/status",
      inlineCSS: true,
      noIDLIn: true,
      noLegacyStyle: false,
      logos: [
      {
        src: "http://www.w3.org/Icons/w3c_home",
        alt: "W3C",
        height: "48",
        width: "72",
        url: "http://www.w3.org/"
      },
      {
        src: "http://www.w3.org/2015/01/ogc_logo.jpg",
        alt: "OGC",
        height: "48",
        width: "115",
        url: "http://www.opengeospatial.org/"
      }
      ],
      noRecTrack: true,
      overrideCopyright: "<p class='copyright'><a href='http://www.w3.org/Consortium/Legal/ipr-notice#Copyright'>Copyright</a> © 2015 <a href='http://www.opengeospatial.org/'>OGC</a> &amp; <a href='http://www.w3.org/'> <abbr title='World Wide Web Consortium'>W3C</abbr> </a><sup>®</sup> (<a href='http://www.csail.mit.edu/'><abbr title='Massachusetts Institute of Technology'>MIT</abbr></a>, <a href='http://www.ercim.eu/'><abbr title='European Research Consortium for Informatics and Mathematics'>ERCIM</abbr></a>, <a href='http://www.keio.ac.jp/'>Keio</a>, <a href='http://ev.buaa.edu.cn/'>Beihang</a>), <abbr title='World Wide Web Consortium'>W3C</abbr> <a href='http://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer'>liability</a>, <a href='http://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks'>trademark</a> and <a href='http://www.w3.org/Consortium/Legal/copyright-documents'>document use</a> rules apply.</p>"
    };
  </script>
  <body>
    <section id='abstract'>
      <p>
        This document is the first deliverable of the <a href="http://www.w3.org/2015/spatial/">Spatial Data on the Web Working Group</a>. It describes uses cases, and requirements for further work that are derived from the use cases.
      </p>
    </section>
    <section id='sotd'>
    </section>
    <section>
      <h2>Introduction</h2>
      <p>
        The mission of the <a href="http://www.w3.org/2015/spatial/">Spatial Data on the Web Working Group</a>, as described in its <a href="http://www.w3.org/2015/spatial/charter">charter</a>, is to clarify and to formalize standards on spatial data on the web. In particular:
        <ol>
        <li>to determine how spatial information can best be integrated with other data on the Web;</li>
        <li>to determine how machines and people can discover that different facts in different datasets relate to the same place, especially when 'place' is expressed in different ways and at different levels of granularity;</li>
        <li>to identify and assess existing methods and tools and then create a set of best practices for their use;</li>
        <li>where desirable, to complete the standardization of informal technologies already in widespread use.</li>
        </ol>
        This document describes the results of the first steps of working towards these goals. Members of the working group and other stakeholders have come up with a number of <a href="#UseCases">use cases</a> that describe how spatial data on the web could work. From these use cases, a number of <a href="#Requirements">requirements</a> for further work are derived. In this document, use cases, requirements and their relationships are described. Requirements and use cases are also related to the <a href="#Deliverables">deliverables</a> of the working group.      
      </p>
      <p>
        The requirements described in this document will be the basis for development of the other four deliverables of the Working Group.
      </p>
    </section>
    </br>
    <section id="Deliverables">
      <h2>Deliverables</h2>
      <p>
      The deliverables of this Working Group are described in the <a href="http://www.w3.org/2015/spatial/charter">Working Group Charter</a>. For convenience those deliverables are replicated in this chapter. The charter remains the authorative source of the definition of deliverables.
      </p>
      <section id="UseCasesAndRequirements">
        <h3>Use Cases and Requirements</h3>
        <p>A document setting out the range of problems that the working groups are trying to solve (this document).</p>
      </section>
      <section id="BestPractices">
        <h3>Spatial Data on the Web Best Practices</h3>
        <p>This will include:
        <ul>
        <li>an agreed spatial ontology conformant to the ISO 19107 abstract model and based on existing available ontologies such as GeoSPARQL, NeoGeo and the ISA Core Location vocabulary;</li>
        <li>advice on use of URIs as identifiers in GI systems;</li>
        <li>advice on providing different levels of metadata for different usage scenarios (from broad sweep metadata to metadata about individual coordinates in a polygon);</li>
        <li>develop advice on, or possibly define, RESTful APIs to return data in a variety of formats including those defined elsewhere, such as GeoJSON, GeoJSON-LD and TopoJSON.</li>
        </ul>
        </p>
      </section>
      <section id="TimeOntologyInOWL">
        <h3>Time Ontology in OWL</h3>
        <p>The WG will work with the authors of the existing Time Ontology in OWL to complete the development of this widely used ontology through to Recommendation status. Further requirements already identified in the geospatial community will be taken into account.</p>
      </section>
      <section id="SSN">
        <h3>Semantic Sensor Network Vocabulary</h3>
        <p>The WG will work with the members of the former Semantic Sensor Network Incubator Group to develop its ontology into a formal Recommendation, noting the work to split the ontology into smaller sections to offer simplified access.</p>
      </section>
      <section id="CoverageInLinkedData">
        <h3>Coverage in Linked Data</h3>
        <p>The WG will develop a formal Recommendation for expressing discrete coverage data conformant to the ISO 19123 abstract model. Existing standard and de facto ontologies will be examined for applicability; these will include the RDF Data Cube. The Recommendation will include provision for describing the subset of coverages that are simple timeseries datasets - where a time-varying property is measured at a fixed location. OGC's WaterML 2 Part 1 - Timeseries will be used as an initial basis.</p>
        <p>Given that coverage data can often be extremely large in size, publication of the individual data points as Linked Data may not always be appropriate. The Recommendation will include provision for describing an entire coverage dataset and subsets thereof published in more compact formats using Linked Data. For example where a third party wishes to annotate a subset of a large coverage dataset or a data provider wishes to publish a large coverage dataset in smaller subsets to support convenient reuse.</p>
      </section>
    </section>
    </br>
    <section id="Methodology">
      <h2>Methodology</h2>
      <p>In order to find out the requirements for the deliverables of the Working Group, use cases were collected. For the purpose of the Working Group, a use case is a story that describes challenges with respect to spatial data on the web for existing or envisaged information systems. It does not  need to adhere to certain standardised format. Use cases are primarily used as a source of requirements, but a use case could be revisited near the time the work of the Working Group will reach completion, to demonstrate that it is now possible to make the use case work.</p> 
      <p>The Working Group has derived requirements from the collected use cases. A requirement is something that needs to be achieved by one or more deliverables and is phrased as a specification of functionality. Requirements can lead to one or more tests that can prove whether the requirement is met.</p>
      <p>Care was taken to only derive requirements that are considered to in scope for the further work of the Working Group. The scope of the Working Group is determined by the <a href="http://www.w3.org/2015/spatial/charter">charter</a>. To help keeping the requirements in scope, the following questions were applied:
      <ol>
      <li>Is the requirement specifically about spatial data on the Web?</li>
      <li>Is the use case including data published, reused, and accessible via Web technologies?</li>
      <li>Has a use case a description that can lead to a testable requirement?</li>
      </ol>
      </p>
    </section>
    </br>
    <section id="UseCases">
      <!--A HTML template for use cases can be found at the end of this section -->
      <h2>Use Cases</h2>
        <p>Use cases that describe current problems or future opportunities for spatial data on the web have been gathered as a first activity of the Working Group. They were mainly contributed by members of Working Group, but there were also contributions from other interested parties. In this chapter these use cases are listed and identified. Each use case is related to one or more Working Group <a href="#Deliverables">deliverables</a> and to one or more <a href="#Requirements">requirements</a> for future deliverables.</p>
        <section id="MeteorologicalDataRescue">
          <h3>Meteorological Data Rescue</h3>
          <p class="contributor">Chris Little, based on scenarios used for the WMO infrastructure requirements.</p>
          <label class="expand" for="uc1"></label>
          <input id="uc1" type="checkbox">
          <div>
          <p>This is really one of several future, but realistic, meteorological scenarios to aim at.</p>
          <p>National Hydro-Meteorological Services around the world are coordinated via the WMO (World Meteorological Organisation), part of the the United Nations system. WMO has the same status as ISO, and its standards and regulatory materials applies to all its 193 national meteorological services and are available in the six working languages ( عربي | 中文 | Fr | Ru | Es | En). WMO has embarked on a long-term (think a decade or so) programme to update the global meteorological operational infrastructure. This is known as the WIS (WMO Information System). The global infrastructure also has aviation, oceanographic, seismic and other users. The WIS includes a global, federated, synchronized, geospatial catalogue, envisaged to encompass all hydro-meteorological data and services. Currently several nodes are operational, cataloguing mainly routinely exchanged observations and forecasts.</p>
          <p>Envisage an environmental scientist in Cambodia, researching the impact of deforestation in Vietnam as part of investigating the regional impacts of climate change. She submits her search keywords, in Cambodian, and receives responses indicating there is some data from the 1950s, printed in a 1960 pamphlet, in the Bibliothèque Nationale, a library in Paris, France, in French. She receives an abstract of some form that enables her to decide that the data are worth accessing, and initiates a request for a digital copy to be sent.</p>
          <p>She receives the pamphlet as a scanned image of each page, and she decides that the quantatitive information in the paper is useful, so she arranges transcription of the tabular numerical data and their summary values into a digital form and publishes the dataset, with a persistent identifier, and links it to a detailed coverage extent, the original paper source, the scanned pages and her paper when it is published. She also incorporates scanned charts and graphs from the orginal pamphlet into her paper.Her organisation creates a catalogue record for her research paper dataset and publishes it in the WIS global catalogue, which makes it also visible to the GEO System of Systems broker portal.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#CRSDefinition"></a>, <a href="#DateTimeDuration"></a>, <a href="#DifferentTimeModels"></a>, <a href="#Discoverability"></a>, <a href="#Linkability"></a>, <a href="#MultilingualSupport"></a>, <a href="#NominalTemporalReferences"></a>, <a href="#PositioningSystem"></a>, <a href="#Provenance"></a>, <a href="#QualityMetadata"></a>, <a href="#ReferenceExternalVocabularies"></a>, <a href="#SensingProcedure"></a>, <a href="#SensorMetadata"></a>, <a href="#SpaceTimeMultiScale"></a>, <a href="#SpatialVagueness"></a>, <a href="#TemporalReferenceSystem"></a>, <a href="#UncertaintyInObservations"></a></p>
        </section>
        <section id="HabitatZoneVerification">
          <h3>Habitat zone verification for designation of Marine Conservation Zones</h3>
          <p class="contributor">Jeremy Tandy</p>
          <label class="expand" for="uc2"></label>
          <input id="uc2" type="checkbox">
          <div>
            <p>The <a href="http://jncc.defra.gov.uk/page-5230">Marine and Coastal Access Act 2009</a> allows for the creation of a type of Marine Protected Area (MPA), called a Marine Conservation Zone (MCZ). MCZs protect a range of nationally important marine wildlife, habitats, geology and geomorphology and can be designated anywhere in English and Welsh inshore and UK offshore waters.</p>
            <p>The designation of a MCZ is dependent on a detailed analysis of the marine environment which results in the definition of geometric areas where a given habitat type is deemed to occur and is published as a habitat map.</p>
            <p>Being a policy statement, it is important to be able to express the provenance of information that was used to compile the habitat map. Moreover, because the marine environment is always changing, it is important to express the time at which this information was collected.</p>
            <p>The information includes:
            <ul>
              <li>acoustic survey</li>
              <li>video (from a video camera towed behind a survey boat)</li>
              <li>biota observations (based on what is observed in the video and from physical collection)</li>
              <li>particle size (sand/mud)</li>
              <li>water column data</li>
              <li>seabed character map: discrete seabed features and backscatter information (from sonar) to determine bottom type</li>
            </ul>
            These information types are varied in type and size. In particular, the acoustic survey (e.g. side-scan sonar) is difficult to manage as these survey results can be many gigabytes in size and cover large areas. A way is needed to refer to just a small part of these coverage data sets that are relevant to a particular habitat zone analysis.
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#GeoreferencedSensorData"></a>, <a href="#Provenance"></a>, ...</p>
        </section>
        <section id="RealtimeWildfireMonitoring">
          <h3>Real-time Wildfire Monitoring</h3>
          <p class="contributor">Manolis Koubarakis</p>
          <label class="expand" for="uc3"></label>
          <input id="uc3" type="checkbox">
          <div>
            <p>This use case is about the wildfire monitoring service of the National Observatory of Athens (NOA) as studied in project <a href ="http://www.earthobservatory.eu/">TELEIOS</a>.The wildfire monitoring service is based on the use of satellite images originating from the SEVIRI (Spinning Enhanced Visible and Infrared Imager) sensor on top of the Meteosat Second Generation satellites MSG-1 and MSG-2. Since 2007, NOA operates an MSG/SEVIRI acquisition station, and has been systematically archiving raw satellite images on a 5 and 15 minutes basis, the respective temporal resolutions of MSG-1 and MSG-2.</p>
            <p>The service active in NOA before TELEIOS can be summarized as follows:
            <ol>
              <li> The ground-based receiving antenna collects all spectral bands from MSG-1 and MSG-2 every 5 and 15 minutes respectively.</li>
              <li>The raw datasets are decoded and temporarily stored in the METEOSAT Ground Station as wavelet compressed images.</li>
              <li>A Python program manages the data stream in real-time by offering the following functionality:
              <ol>
                <li>Extract and store the raw file metadata in an SQLite database. This metadata describes the type of sensor, the acquisition time, the spectral bands captured, and other related parameters. Such a step is required as one image comprises multiple raw files, which might arrive out-of-order.</li>
                <li>Filter the raw data files, disregarding non-applicable data for the fire monitoring scenario, and dispatch them to a dedicated disk array for permanent storage.</li>
                <li>Trigger the processing chain by transferring the appropriate spectral bands via FTP to a dedicated machine and initiating the following steps: (i) cropping the image to keep only the area of interest, (ii) georeferencing to the geodetic reference system used in Greece (HGRS 87), (iii) classifying the image pixels as "fire" or "non-fire" using appropriate algorithms, and finally (iv) exporting the final product to raster and vector formats (ESRI shapefiles).</li>
                <li>Dispatch the derived products to the disk array and additionally store them in a PostGIS database system.</li>
              </ol></li>
            </ol>
            It would be interesting for NOA to see how to use the standards developed by this working group to achieve the following:
            <ul>
            <li>Improve the thematic accuracy of generated products.</li>
            <li>Generate thematic maps by combining the generated products with other kinds of data such as: Corine Land Cover, the Administrative Geography of Greece, OpenStreetMap data and Geonames.</li>
            </ul>
            This use case is further discussed in <a href="http://cgi.di.uoa.gr/~koubarak/publications/edbt2013.pdf">this paper</a>.<br>
            The service is operational <a href = "http://ocean.space.noa.gr/seviri_u/fend_new/index.php">here</a>.<br>
            Some data that can be used by the service can be found <a href="http://linkedopendata.gr/">here</a>.
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a></p>
          <p class="relatedRequirements"> <a href="#CRSDefinition"></a>, <a href="#Linkability"></a>, <a href="#Provenance"></a>, <a href="#SensorMetadata"></a>, <a href="#DynamicSensorData"></a></p>
        </section>
        <section id="DiachronicBurntScarMapping">
          <h3>Diachronic Burnt Scar Mapping</h3>
          <p class="contributor">Manolis Koubarakis</p>
          <label class="expand" for="uc4"></label>
          <input id="uc4" type="checkbox">
          <div>
          <p>This use case was studied by the National Observatory of Athens (NOA) in project <a href ="http://www.earthobservatory.eu/">TELEIOS</a>. The burnt scar mapping service is dedicated to the accurate mapping of burnt areas in Greece after the end of the summer fire seasons, using Landsat 5 TM satellite images. The processing chain of this service is divided into three stages, each one containing a series of modules.</p>
          <p>The pre-processing stage is dedicated to (i) identification of appropriate data, downloading and archiving, (ii) georeferencing of the received satellite images, and (iii) cloud masking process to exclude pixels “contaminated” by clouds from the subsequent processing steps.</p>
          <p>The core processing stage comprises (i) a classification algorithm which identifies burnt and non-burnt sets of pixels, (ii) a noise removal process that is necessary to eliminate isolated pixels that have been classified wrongfully as burnt, and (ii) converting the raster intermediate product to vector format.</p>
          <p>Finally, the post-processing stage consists of (i) a visual refinement step to ensure product thematic accuracy and consistency, (ii) attribute enrichment of the product by overlaying the polygons with geoinformation layers and finally (iii) generation of thematic maps.It would be interesting for NOA to see where the standards to be developed in this working group could be used.</p>
          <p>The service is operational <a href="http://ocean.space.noa.gr/seviri_u/fend_new/index.php">here</a>.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a></p>
          <p class="relatedRequirements"><a href="#CRSDefinition"></a>, <a href="#Linkability"></a>, <a href="#Provenance"></a>, <a href="#SensorMetadata"></a>, ...</p>
        </section>
        <section id="HarvestingLocalSearchContent">
          <h3>Harvesting of Local Search Content</h3>
          <p class="contributor">Ed Parsons</p>
          <label class="expand" for="uc5"></label>
          <input id="uc5" type="checkbox">
          <div>
          <p>This is a rather generic and broad use case, relevant to Google but clearly also relevant to anyone interesting in machine processing of html referring to about locations and activities which take place at those locations. Local search providers spend much time and effort creating databases of local facilities, businesses and events.</p>
          <p>Much of this information comes from web pages published on the public web, but in an unstructured form. Previous attempts at harvesting this information automatically have meet with only limited success, currently alternative approaches involve business owners manually adding structured data to dedicated portals. This approach although clearly an improvement does not really scale and there are clearly issues in terms of data sharing and freshness.</p>
          <p>The information of interest includes:
          <ul>
          <li>The facilities address</li>
          <li>The type of business/activity</li>
          <li>Opening hours</li>
          <li>Date, time and duration duration of events</li>
          <li>Telephone, e-mail and website details</li>
          </ul>
          </p>
          <p>Complexities to this include multiple address standards, the differences between qualitative representations of place, and precise spatial co-ordinates, definitions of activities etc.</p>
          <p>Ultimately these web pages should become the canonical source of local data used by all web users and services.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>,</p>
          <p class="relatedRequirements"><a href="#DateTimeDuration"></a>,</p>
        </section>
        <section id="LocatingAThing">
          <h3>Locating a thing</h3>
          <p class="contributor">Ed Parsons</p>
          <label class="expand" for="uc6"></label>
          <input id="uc6" type="checkbox">
          <div>
          <p>With the increasing availability of small, mobile location aware devices the requirement to identify a location human terms is becoming more important. While the determination of sensor in space to a high level of precision is a largely solved problem we are less able to express the location in terms meaningful to humans. The fact that the Bluetooth-LE tracker attached to my bag is at 51.4256853,-0.3317991,4.234500 is much less useful than the description, "Under your bed at home". At others times the location descriptions "24 Bridgeman Road, Teddington, TW11 8AH, UK" might be equally valid, as might "Teddington", "South West London", "England", "UK", "Inside", "Where you left it Yesterday", "Upstairs", "45 minutes from here" or "150 metres from the Post Office".</p>
          <p>A better understanding of how we describe places in human terms, the hierarchical nature of places and the fuzzy nature of many geographical entities will be needed to make the "Internet of Things" manageable. A new scale of geospatial analysis may be required using a reference frame based on the locations of individuals rather than a global spherical co-ordinate, allowing a location of your keys and their attached bluetooth tag to be described as "in the kitchen".</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="PublishingGeographicalData">
          <h3>Publishing geographical data</h3>
          <p class="contributor">Frans Knibbe</p>
          <label class="expand" for="uc7"></label>
          <input id="uc7" type="checkbox">
          <div>
          	<p>This use case is for representing the perspective of a party that is interested in publishing data on the web and wants to do it right with respect to the geographical component of the data. The point of this use case is that it would be good to remove barriers that stand in the way of more spatial data becoming available on the web.</p>
          	<p>A data publisher could have the following questions:</p>
	         <ol>
		         <li>How should I publish vector data? What is the best encoding to use?</li>
	         	<li>How should I publish raster data?</li>
	         	<li>How do I make the CRS known?</li>
	         	<li>How do I make the spatial resolution/level of detail/accuracy known?</li>
	         	<li>Which data publishing software has good support of geographical data types and geographical functions?</li>
	         	<li>Which data publishing software has good performance when it comes to spatial operations on data?</li>
	         </ol>
				<p>From the last two questions it follows that the WG could also be involved in enabling conformance testing and stimulating development of benchmarks for software.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"><a href="#3DSupport"></a>, <a href="#BoundingBoxCentroid"></a></p>
        </section>
        <section id="ConsumingGeographicalDataInAWebApplication">
          <h3>Consuming geographical data in a web application</h3>
          <p class="contributor">Frans Knibbe</p>
          <label class="expand" for="uc8"></label>
          <input id="uc8" type="checkbox">
          <div>
          <p>This use case is somewhat complementary to use case <a href="">PublishingGeographicalData</a>. It takes the consumer perspective, specifically that of a developer of a web application that should visualise data and allow some kind of user interaction. The hypothetical web application has little or no prior knowledge about the data it will encounter on the web, but should be able to do something meaningful with any spatial data that are encountered, like drawing data on a map or rendering the data in a 3D city scape.</p>
          <p>The point of this use case is that in order for spatial data on the web to be succesful, supply and demand must be balanced to create a positive feedback loop. High quality data must be available in high quantitities but those data must also be highly usable for experts as well as non-experts.</p>
          <p>A web application developer could have the following questions:
          <ol>
            <li>How do I find geographical data on the web?</li>
            <li>How can I tell what kind of spatial data I will get? Raster or vector? 2D or 3D?<li>
            <li>Which encoding of vector data can I expect?</li>
            <li>Which encoding of raster data can I expect?</li>
            <li>Can I get the data with coordinates that match the coordinate system of my map?</li>
            <li>What is the spatial extent of this dataset/collection of resources/resource?</li>
            <li>How can I filter data to get the most appropriate spatial representation of a resource/collection of resources?</li>
            <li>How can I use spatial data on the web without having to take a four year academic course first?</li>
            <li>Which spatial operations does this SPARQL endpoint support?</li>
            <li>Can I use spatial operations in federated queries?</li>
            <li>How can I ensure responsiveness of my application (low wait times when accessing data)?</li></p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities">
          <h3>Enabling publication, discovery and analysis of spatiotemporal data in the humanities</h3>
          <p class="contributor">Frans Knibbe, Karl Grossner</p>
          <label class="expand" for="uc9"></label>
          <input id="uc9" type="checkbox">
          <div>
          <p>Note this use case shares characteristics with <a href="PublishingCulturalHeritageData"></a>.</p>
          <p>
          A research endeavour that has just started tries to stimulate researchers in the various fields of the humanities to make research data available in such a way that the data are and remain usable by other researchers, in such a way that the data may be used for purposes other than those envisaged by the original researcher. The emphasis lies on spatiotemporal data, because they are nice to visualise (a map with a time slider) and because it is thought that it would be interesting to try to discover patterns in time and/or space in interlinked distributed data sets.</p>
          <p>This project has the following aspects that seem relevant to this Working Group:</p>
          <ol>
          <li>Technologies must be easy to implement for people that generally do not have a high affinity with IT. This goes for data publishing as well as data consumption.</li>
          <li>References to time and space are often inexact or have shifting frames of reference, so simple encodings like basic geo or ISO 8601 do not suffice.</li>
          <li>References to time and space do need to be as exact as possible, to enable automatic discovery of spatiotemporal patterns.</li>
          <li>Datasets do not just need to be published, they need to be easily discovered too, using spatial and/or temporal filters.</li>
          </ol>
          </p>
          <p>Adding examples below relevant to items 2 and 3 above, from one existing scholarly web application case, which may contribute to a more general (i.e. not necessarily historical) requirement for representing several types of uncertainty: imprecision, probability, confidence. Standards for gazetteers -particularly historical (temporal) ones- are non-existent, although several projects with potentially global reach are underway. It will be helpful to have this Working Group in dialog with developers for such projects as <a href="http://pelagios-project.blogspot.com/p/about-pelagios.html">Pelagios</a>, <a href="http://loc.gazetteer.us/">Library of Congress</a>, <a href="http://pleiades.stoa.org/">Pleiades</a>, and Past Place (cf. <a href="http://www.port.ac.uk/department-of-geography/staff/humphrey-southall.html">Humphrey Southall</a>).
          <h4>Spatial</h4>
          <ul>
            <li>A set of life path data were developed for a kinship network of 30,000 individual Britons linked by birth and marriage. Spatial data for the locations of life events has several levels of granularity, from street address (10 Downing Street) to country (China). How can spatial containment relationships for places be expressed so that spatial-temporal contemporaneity be calculated?</li>
            <li>References to places in historical works are often limited to toponyms (i.e. absent geometry or precise spatial relations), and qualified by such terms as "near," and "north of." How can these be indexed spatially so as to be discoverable?</li>
          </ul>
          <h4>Temporal</h4>
          <ul>
            <li>As with spatial data, historical sources contain temporal references at varying granularity. A single data set may contain expressions for exact dates, months, or years -- or ranges containing a mix of any of those.</li>
            <li>Temporal references are frequently inexact, or relational with variable precision. The above referenced data set has a mix, including "around March 1832," "before 1750," "after WW II."</li>
          </ul>
          </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a></p>
          <p class="relatedRequirements"><a href="#NominalTemporalReferences"></a>, <a href="#TemporalMultiScale"></a>, <a href="#TemporalVagueness"></a></p>
        </section>
        <section id="PublishingGeospatialReferenceData">
          <h3>Publishing geospatial reference data</h3>
          <p class="contributor">Clemens Portele</p>
          <label class="expand" for="uc10"></label>
          <input id="uc10" type="checkbox">
          <div>
          <p><i>This use is based on the <a href="http://www.elfproject.eu/documentation">European Location Framework (ELF)</a></i></p>
          <p>Mapping and cadastral authorities maintain datasets that provide geospatial reference data. Reference data is data that a user/developer uses to provide location for her own data (by linking to it), by providing context information about a location (overlaying his data over a background map), etc.</p>
          <p>A key part of this is persistent identifiers for the published data to allow linking to the reference data. Let's assume that http URIs following the <a href="http://www.w3.org/TR/cooluris/">Cool URI note</a> are used as identifiers.</p>
          <p>In ELF - and INSPIRE - reference data is typically published using a web service by the national authority. In ELF this is an OGC Web Feature Service. To provide access to the different datasets via a single entry point, all the national services are made available via a proxy web service that also handles authentication etc. In addition, it is foreseen to publish the reference data in other commonly used web-based platforms for geospatial data to simplify the use of the data - developers and users can use the tools and APIs they are familiar with.</p>
          <p>As a result, the same administrative unit (to pick an example) is basically available via multiple (document) URIs: via the national web service, the ELF proxy web service and web services of the other platforms. Different services will support different representations (GML, JSON, etc). The web services may not be accessible by everyone and different users will have access to different document URIs.</p>
          <p>Which real-world object and document URIs for the administrative unit should be maintained and what does a GET return in order <ul>
          <li>to support linking other data to the administrative unit,</li>
          <li>to deliver the document and representation that the user expects when dereferencing the link?</li>
          </ul>
          A related challenge is that today such links are often implicit. For example, a postal code or a statistical unit code is a property in the other data, but the link is not explicit like a http URI. What is a good practice to make use of such implicit links? Should they be converted to http URIs to be explicit or are there better ways (e.g. additional context that provide information about the semantics and a pattern how to construct dereferencable URIs)?
          </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="IntegrationOfGovernmentalAndUtilityDataToEnableSmartGrids">
          <h3>Integration of governmental and utility data to enable smart grids</h3>
          <p class="contributor">Frans Knibbe</p>
          <label class="expand" for="uc11"></label>
          <input id="uc11" type="checkbox">
          <div>
          <p>The research project <a href="http://www.cerise-project.nl/index.php?lang=en">CERISE-SG</a> aims to integrate data from different domains: government, energy utilities and geography, in order to enable establishment of smart energy grids.</p>
          <p>The project has recognized Linked Data as an appropriate concept for integration of data from separate semantic domains. One approach of achieving cross-domain interoperability is to switch from domain-specific semantics to common semantics. For example, the concept of an address has its own definitions in governmental standards and utility standards. Using a common definition improves interoperability.</p><p>An example of a domain model that is an international standard in electric utilities is the <a href="http://en.wikipedia.org/wiki/Common_Information_Model_(electricity)">Common Information Model (CIM)</a>. Its data model provides definitions for an important entity: the electricity meter. These meters provide useful data on consumption and production of energy. If it is possible to view these devices as sensors, it could be possible to move from domain specific semantics (CIM) to common semantics (SSN), and to have ready linkage to geographical semantics (location and network topology). What is required in this case is a low-threshold way of using sensor semantics, because people involved in integration of data from multiple domains should not be burdened with having to grasp the full complexity of each domain.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SemanticSensorNetworkVocabulary"></a></p>
          <p class="relatedRequirements"> <a href="#SensorMetadata"></a>, ...</p>
        </section>
        <section id="UsingSpatialDataFromTheWebInGISSystemsDuringEmergencyResponseOperations">
          <h3>Using spatial data from the web in GIS systems during emergency response operations</h3>
          <p class="contributor">Bart van Leeuwen</p>
          <label class="expand" for="uc12"></label>
          <input id="uc12" type="checkbox">
          <div>
          <p>During Emergency response operations the only spatial data available to emergency response services is the predefined data in their GIS warehouses. This while the incidents and accidents handled by emergency response services are by nature unpredictable, it is impossible to determine on forehand which data you might need. Ad-hoc data available on the web with a spatial component is not easily used right now, neither can the available data about a incident be easely shared over the web.</p>
          <p>A related issue is that the relation between the data in the GIS warehouses is only spatial, while most of the time there is an <a href="DutchBaseRegistry">adminstrative relation</a> as well.</p>
          <p>Under the umbrella of various projects a first attempt has been made to at least share definitions of the terminology used by various emergency response services, both national and cross border. This resulted in the start of a project called the <a href="http://www.firebrary.com/">Firebrary</a>, now the terminology and definitions are available on the web as linked data as SKOS. Still linking from the spatial data to these definitions and vice versa is not standardized.</p>
          <p>What seems to be missing is a way to define a relationship between GIS data (in e.g. WFS services) and data on the web and vice versa, express that a certain linked data resource is also available through a GIS service (rdfs:seeAlso is too limited imho) or describe the spatial component in the linked data directly.</p>
          <p>Being able to plot and exchange data about active incidents through the web and visualize them in GIS tools with open standards would be a huge leap foreward for Emergency response services.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="PublicationOfAirQualityDataAggregations">
          <h3>Publication of air quality data aggregations</h3>
          <p class="contributor"> Alejandro Llaves, Miguel Angel García-Delgado (OEG-UPM), Rubén Notivol, Javier Celma (Ayuntamiento de Zaragoza)</p>
          <label class="expand" for="uc13"></label>
          <input id="uc13" type="checkbox">
          <div>
          <p><b>What:</b> The local authorities of Zaragoza (Spain) want to publish the air quality data of the city. Each observation station has a spatial location described with an address. The dataset contains hourly observations and daily aggregations of different gases, e.g., SO2, NO2, O3, CO, etc.</p>
          <p><b>How:</b> We use the <a href="http://www.w3.org/ns/locn">Location Core vocabulary</a> to model the address, e.g. :station locn:address "C/ Gran Vía (Paraninfo)"^^xsd:string. We use xsd:dateTime to represent hourly observations, e.g. :obs ssn:observationResultTime "2003-03-08T11:00:00Z"^^xsd:dateTime.</p>
          <p>Open challenges: The combination of hourly observations and daily aggregations in the same dataset may cause confusion because the granularity of the observation is not explicit. For daily aggregations, we suggest using time:Interval from the Time Ontology. To make the temporal modelling more homogeneous, time:Instant could be used for the hourly observations. [LINK TO DATA SAMPLE TO BE ADDED]</p>
          </div>
          <p class="relatedDeliverables"><a href="#SemanticSensorNetworkVocabulary"></a>, <a href="#TimeOntologyInOWL"></a></p>
          <p class="relatedRequirements"><a href="#DateTimeDuration"></a>, <a href="#ModelReuse"></a>, <a href="#ObservationAggregations"></a>, <a href="#ReferenceExternalVocabularies"></a>, ...</p>
        </section>
        <section id="PublicationOfTransportCardValidationAndRechargingData">
          <h3>Publication of transport card validation and recharging data</h3>
          <p class="contributor">Alejandro Llaves (OEG-UPM)</p>
          <label class="expand" for="uc14"></label>
          <input id="uc14" type="checkbox">
          <div>
          <p><b>What:</b> The Regional Transport Consortium of Madrid (CRTM) wants to make available data about transport card validations and transport card recharging. In the case of transport card validations, the NFC sensors are located on buses, and at the entrance and (some) exit points of metro stations. The observation value of a validation includes data related to the transport card, such as the card identifier and the user profile. The sensors for transport card recharging are ATMs and ticket selling points distributed around Madrid. The observation value of a recharging includes the card identifier and the type of recharging.</p>
          <p><b>How:</b> To model transport card validations, we consider two observed properties: user entry (EntradaUsuario) and user exit (SalidaUsuario). Validation sensors at metro stations have a fixed location and a unique identifier, e.g. 02_L12_P2. A bus validation sensor is moving continuously, so for the sake of pragmatism, there is a unique sensor identifier for each bus stop in every line, e.g. 03_L20_P837. Those identifiers point to an address and geographic coordinates. The observed property when a user adds money to her transport card is the act of recharging (CargaTTP). In both cases, validation and recharging observations, the feature of interest is the transport card.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SemanticSensorNetworkVocabulary"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="CombiningSpatialRDFDataForIntegratedQueryingInATriplestore">
          <h3>Combining spatial RDF data for integrated querying in a triplestore</h3>
          <p class="contributor">Matthew Perry (Oracle)</p>
          <label class="expand" for="uc15"></label>
          <input id="uc15" type="checkbox">
          <div>
          <p>RDF datasets with spatial components are becoming more common on the Web. Many applications could benefit from the ability to combine, analyze and query this data with an RDF triplestore (or across triplestores with a federated query). Challenges arise, however, when trying to integrate such datasets.
          <ul>
            <li>Inconsistent, incomplete, and non-standard metadata descriptions of spatial data</li>
            <li>Different representations of geometry data across different datasets</li>
            <li>Different spatial reference systems used across different datasets</li>
            <li>Different scales used across different datasets</li>
          </ul><p>For example, <a href="http://data.ordnancesurvey.co.uk/">Ordnance Survey</a> linked data uses British National Grid SRS and represents geometries with an Ordnance Survey-developed ontology, and <a href="http://linkedgeodata.org/Datasets">LinkedGeoData</a> uses WGS84 longitude latitude and represents geometries as GeoSPARQL WKT literals.</p>
          <p>Best practices in the following areas would help make integration more straightforward.
          <li>Agreed-upon vocabulary for metadata about spatial datasets</li>
          <li>Agreed-upon URIs for common spatial reference systems</li>
          <li>Recommendations for a default, canonical spatial reference system for spatial data published on the web</li>
          <li>Recommendations for serializing geometries as RDF</li>
          <p>Consistent metadata descriptions about spatial datasets will take out a lot of guess work when combining datasets, and standard URIs for spatial reference systems will be an important part of this metadata description. A recommended canonical SRS would make combining datasets more efficient by eliminating the coordinate transformation step, which would make federated GeoSPARQL queries more feasible.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="DutchBaseRegistry">
          <h3>Dutch Base Registry</h3>
          <p class="contributor">Linda van den Brink</p>
          <label class="expand" for="uc16"></label>
          <input id="uc16" type="checkbox">
          <div>
          <p>Dutch government data is for a large part open data. However, at the moment the data is difficult to find, and it cannot be easily linked to other data. It is not helping that most registrations are making use of their heavy backoffice standards for opening their data. These problems are counteracted by copying data of others, involving heavy expenses for collecting, converting and synchronising the data, or by building expensive national provisions. The result is an abundance of copies and much doubt regarding the authenticity of the information.</p>
          <p>A better solution would be to make the authentic data permanently available as linked data, so that everyone can use it and the datasets can be interlinked, resulting in more coherence and improved traceability and no more need for copying and synchronisation.</p>
          <p>There are now 13 Dutch ‘base registries’ containing government reference data: e.g.
          <ul>
            <li>BAG (Buildings and Adresses)</li>
            <li>NHR (Businesses, organizations)</li>
            <li>BRP (Citizens)</li>
            <li>BGT (large scale topography)</li>
            <li>BRT (small scale topography)</li>
            <li>BRK (cadastre)</li>
            <li>WOZ (building tax)</li>
          </ul>
          A lot of these have geospatial content or refer to geospatial resources in other base registries (such as addresses). At the moment these references are informal and often incorrect or outdated. This means there is a need to express geospatial content in linked data (i.e. a standard vocabulary) and to perform spatial queries over linked data.</p>
          <p>Geometries, especially lines and polygons, may contain many coordinates. For example, a municipal boundary could easily contain more than 1500 coordinate pairs. Compared to non-geometric properties, this can result in large amounts of data to transfer and process. The coordinates can easily be 95% of all data of an object when using polygons. The question rises whether there is a need for performance optimization and/or compression techniques for large amounts of coordinates. If so, there could also be a need to standardize such a technique, similar to the PNG format for encoding images.</p>
          <p>Coordinate reference systems (CRS) are to geo-information what character encodings are to text. If you don’t know which CRS is used, you can’t use the coordinates. Different CRSs exist for a reason: localized CRSs provide more precise coordinates for a certain part of the globe. It is not possible for a global CRS to be as precise, for example because the continental plates move a few centimetres every year. For large scale data and applications this continental drift could be very relevant over time. Take for example the boundary of cadastral parcels. If this drift is not taken into account, there could be issues if parcel boundaries that were established e.g. 10 years ago are overlaid over recently acquired aerial imagery with high accuracy (e.g. 10 cm). There could be visual differences, while the actual situation did not change.</p>
          <p>While the possibility to use different CRSs hinders interoperability (datasets using different CRSs cannot be easily combined, a complex transformation is necessary), on the other hand this option is perhaps needed for use cases where a high precision of coordinates is important. The BGT (large scale topography) is an example of such a use case.</p>
          <p>A prototype application, based on linked data, where BGT, BAG, NHR and WOZ data is combined, is <a href="http://almere.pilod.nl/bgtld">here</a>. BAG linked data is <a href="http://bag.kadaster.nl">here</a> (“Begrippen”: the vocabulary; “BAG Data”: the data)</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="PublishingCulturalHeritageData">
          <h3>Publishing Cultural Heritage Data</h3>
          <p class="contributor">Lars G. Svensson</p>
          <label class="expand" for="uc17"></label>
          <input id="uc17" type="checkbox">
          <div>
          <p>Cultural Heritage Data such as library authority files are increasingly being published as Linked (Open) Date. Those datasets contain, among other entities, descriptions of spatio-temporal events such as <i>World War I</i>, the <i>Birth of Albert Einstein</i> (date and place) or <i>Martin Luther's pinning of his 95 theses</i>. The problem is that most of the spatio-temporal information is inexact. This inexactness ranges from time spans (<i>second quarter of the 9th century</i>, e.g. approx. 825-850, which also could be 823 or 852) to geographic entities such as <i>Renaissance Italy</i> (what did Italy look like at that time, and to what extent is the Italian renaissance as a time period different from the English?).</p>
          <p>When cultural heritage institutions put their data on the web, the staff members mapping their data to web standards often do not have expertise in temporal or geospatial data formats. Formats such as WKT are standardised but it is difficult to know if the mapping from the local data source is done correctly. A validator for commonly used formats such as WKT or GeoJSON would prove helpful.</p>
          <p>Challenges include:
          <ol>
          <li>There is no framework available to describe fuzzy temporal information. ISO 8601 and the related XSD datatypes assume a precision that cannot be supplied by the data publishers.</li>
          <li>In addition to that, OWL reasoning over cultural heritage datasets is severely hampered since OWL only accepts the datatypes xsd:dateTime and xsd:dateTimeStamp as temporal datatypes (cf. <a href="http://www.w3.org/TR/owl2-syntax/#Time_Instants%7COWL">Time Instants</a>).</li>
          <li>Little or no possibilities to perform validation of temporal and/or spatial data formats (e.g. WKT).</li>
          </ol>
          Note: This use case has similarities to <a href="#EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities"></a>.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#CoverageInLinkedData">, <a href="#SpatialVagueness"></a></p>
          <p class="relatedRequirements"><a href="#NominalTemporalReferences"></a>, <a href="#TemporalMultiScale"></a>, <a href="#TemporalVagueness"></a></p>
        </section>
        <section id="DisseminationOf3DGeologicalData">
          <h3>Dissemination of 3D geological data</h3>
          <p class="contributor">Rachel Heaven</p>
          <label class="expand" for="uc18"></label>
          <input id="uc18" type="checkbox">
          <div>
            <p>The British Geological Survey (BGS), like all Geological Survey Organisations (GSOs), has as one of its principal roles to be the primary provider of geoscience information within its national territory. Increasingly the information provided is digital and dissemination is over the internet, and there is a trend towards making more information freely available. For BGS’s 2D information this requirement has been met by the provision of <a href="http://bgs.ac.uk/data/services/wms.html">various OGC web map services</a>.</p>
            <p>However, geological units and structures are three-dimensional bodies and their traditional depiction on two-dimensional geological maps leads to a loss of information and the requirement of quite a high level of geological understanding on the part of the user to interpret them. The geoscience data user community includes scientific users, but also includes many other stakeholders such as exploration companies, civil engineers, local authority planners, as well as the general public. It is therefore the aim of many Geological Surveys, including BGS, to move towards the provision of geological information as spatial 3D datasets on the web that are accessible and useable by non-experts.</p>
            <p>We have implemented a few ways of disseminating the 3D data on the web (<a href="http://www.bgs.ac.uk/services/3Dgeology/lithoframeSamples.html">http://www.bgs.ac.uk/services/3Dgeology/lithoframeSamples.html</a>, <a href="http://www.bgs.ac.uk/services/3Dgeology/virtualBoreholeViewer.html">http://www.bgs.ac.uk/services/3Dgeology/virtualBoreholeViewer.html</a>,<a href="http://earthserver.bgs.ac.uk/">http://earthserver.bgs.ac.uk/</a>, investigation of augmented reality smartphone application) but the remaining issues are
            <ul>
              <li>user should not need any special software for discovery and assessment purposes</li>
              <li>user can subset the data by x,y,z limits</li>
              <li>user can overlay their own area/volume of interest on the model (e.g. for tunnelling projects)</li>
              <li>user may have to overlay their own (or an open data) DTM if the model is built using a non-open data DTM to represent complex geology (folding, faulting, intrusions etc) and varying data resolution the delivery method must be able to handle triangulated irregular networks (TINs) and heterogeneous resolution voxel grids. </li>
            </ul>
            If there existed a best practise or standard way of publishing this sort of data then it would encourage development of applications on the web to handle them. The datasets that BGS is generating are
            <ul>
              <li>3D spatial models of rock type and/or lithology currently represented as stacks of 2d subsurface grids representing the interfaces between different layers.</li>
              <li>3D voxel datasets of x,y,z grid cell and geological, physical or chemical property (+ associated uncertainty).</li>
              <li>3D LIDAR point cloud data e.g. of retreating cliff faces, underground mine structures</li>
            </ul>
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="PublicationOfRawSubsurfaceMonitoringData">
          <h3>Publication of Raw Subsurface Monitoring Data</h3>
          <p class="contributor">Rachel Heaven</p>
          <label class="expand" for="uc19"></label>
          <input id="uc19" type="checkbox">
          <div>
          <p>The UK Government is funding a new Energy Security and Innovation Observing System for the Subsurface (ESIOS). ESIOS will consist of a group of science research facilities where new subsurface activities such as fracking (hydraulic fracturing) for shale gas can be tested and monitored under controlled conditions. This research will address many of the environmental issues that need to be answered for the development of the UK’s home-grown, secure energy solutions. This includes carbon capture and storage, geothermal energy, nuclear waste disposal, underground coal gasification and underground gas storage.</p>
          <p>Data will be collected from monitoring boreholes and from surface, airborne and satellite sensors. The raw scientific data will be published freely online, possibly in real-time or near real-time, to encourage transparency and public confidence in the industry, and to provide underpinning science for regulation.</p>
          <p>The scientific data will consist of:
          <ul>
            <li>Location data for the sensor facilities</li>
            <li>Time series data consisting of x,y,z (depth), time, and an observed property (e.g. porosity, resistivity, density, methane content, fracture orientation, groundwater flow direction, seismic ground motion).</li>
          </ul>
          We want to be able to publish this raw data on the web in such a way that it can be easily consumed by third party web applications for visualisation, spatio-temporal filtering, statistical analysis and alerts.</p>
          <p>(Another similar use case is for publication of geomagnetic monitoring data, for which the primary outputs are time series tables or graphs, and the location data for the observation station is relatively simple and low accuracy)</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a></p>
          <p class="relatedRequirements"><<a href="#SensorDataTimeSeries"></a>, <a href="#3DSupport"></a>, <a href="#TimeSeries"></a></p>
        </section>
        <section id="UseOfAPlaceNameOntologyForGeo-parsingTextAndGeo-enablingSearches">
          <h3>Use of a place name ontology for geo-parsing text and geo-enabling searches</h3>
          <p class="contributor">Rachel Heaven</p>
          <label class="expand" for="uc20"></label>
          <input id="uc20" type="checkbox">
          <div>
          <p>BGS has valuable geoscience data in text form dating back 180 years, which is gradually being scanned and OCR to make it more accessible and searchable. Much of the information in the reports concerns observations or interpretations made at a location or about a named geological feature. We would like the relevant information in those documents to be retrievable from a web search using coordinate limit criteria or using a place name criteria, so this use case requires a place name ontology (or federated ontologies).</p>
          <p>For BGS's purposes the ontology should contain historical place names, named subsurface geological features (e.g. Widmerpool Gulf), palaeogeographic place names, and named submarine features (e.g. <a href="http://www.gebco.net/data_and_products/undersea_feature_names/">GEBCO undersea feature names </a>).</p>
          <p>To extend the capabilities into the vertical dimension then the ontology should also contain the names of qualitative earth realms (vertical divisions within the atmosphere, ocean and solid earth – such as in <a href=" https://sweet.jpl.nasa.gov/">the SWEET ontology</a>).</p>
          <p>To extend the capabilities into the time dimension then the ontology should also contain the names of historical and geological time periods (e.g. <a href="https://www.seegrid.csiro.au/wiki/CGIModel/GeologicTime#GeologicTime_XML">https://www.seegrid.csiro.au/wiki/CGIModel/GeologicTime#GeologicTime_XML</a>, used in a recent example of geological age name parser at <a href="http://www.agenames.org">http://www.agenames.org</a>)</p>
          <p>With a resource like this, all text resources could be parsed to locate them in time and space.</p>
          <p>Each named feature should have a spatial attribute, either as topological relations to other named features, or as spatial-temporal extent appropriate for various scales and with appropriate uncertainties (i.e. fuzzy definitions of geometry and time periods). Versioning will be important e.g. for administrative boundaries that change frequently.</p>
          <p>(NB <a href="http://www.geonames.org/">Geonames</a> goes much of the way to meeting this requirement)</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a></p>
          <p class="relatedRequirements"><a href="#DifferentTimeModels"></a>, <a href="#3DSupport"></a>, <a href="#TemporalReferenceSystem"></a>, <a href="#ValidTime"></a></p>
        </section>
        <section id="DrivingToWorkInTheSnow">
          <h3>Driving to work in the snow</h3>
          <p class="contributor">Cory Henson (Bosch RTC)</p>
          <label class="expand" for="uc21"></label>
          <input id="uc21" type="checkbox">
          <div>
            <p>Consider the following wildly-fictional scenario: Sue is driving to work in the snow on a cold Pittsburgh morning. On entry, her car recognizes the cold weather and automatically heats the interior to Sue's preferred temperature and turns on the defrost to clear the frost from the wind-shield. On the way, the snow causes significant traffic delay on her route forcing her to re-schedule an early morning meeting. In response, the car suggests she stop at her favorite nearby coffee shop for a Flat White until the roads are clear.</p>
            <p>The scenario above requires access to multiple types of observation, spatial, and temporal data which may be local to the car or available on the Web.</p>
            <p>The different types of observation data may include:
            <ul>
              <li>sensed environmental observations (e.g,. freezing-temperature, frost-on-windshield)</li>
              <li>user behavior observations (e.g., Sue sets the thermostat to 75F, Sue stops at the coffee shop, Sue updates her calendar)</li>
              <li>bservations on the Web (e.g., current weather conditions, traffic conditions)</li>
            </ul>
            The different types of spatial data may include:
            <ul>
              <li>points-of-interest (e.g., home, work, coffee shop)</li>
              <li>spatial relations (e.g., coffee shop is NEAR Sue's current location)</li>
            </ul>
            The different types of temporal data may include:
            <ul>
              <li>calendar events (e.g., Sue's meeting on calendar)</li>
              <li>schedules (e.g., schedule when the coffee-shop is open)</li>
              <li>temporal relations (e.g., the predicted time to reach work occurs after the beginning of a scheduled meeting)</li>
            </ul>
            In addition, the car uses light-weight communication protocols, such as CoAP and/or MQTT, to exchange data (i.e., observations, spatial, and temporal data) between networked components.</p>
            <p>This scenario may face the following general challenges for representing, managing, and querying observation data:
            <ul>
              <li>discover observation streams within a given spatial context (and matching some criteria)</li>
              <li>query for observations within a given spatiotemporal context (and matching some criteria)</li>
              <li>publish and subscribe to an observation stream within a given spatial context (and matching some criteria)</li>
              <li>filter an observation stream based on given set of criteria (e.g., quality, feature-of-interest, observed-property)</li>
              <li>represent data with a small syntactic footprint (for exchange between resource-constrained devices)</li>
              <li>integration of SSN with existing, well-known, IoT protocols (CoAP, MQTT, etc.)</li>
              <li>represent "high-level" qualitative observations (such as observations of user behavior, e.g., Sue stopped at the coffee shop)</li>
            </ul>
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#CitizensAsSensors"></a>, <a href="#DateTimeDuration"></a>, <a href="#Discoverability"></a>, <a href="#DynamicSensorData"></a>, <a href="#GeoreferencedSensorData"></a>, <a href="#MovingFeatures"></a>, <a href="#NominalObservations"></a>, <a href="#NominalTemporalReferences"></a>, <a href="#SensorMetadata"></a></p>
        </section>
        <section id="IntelligentTransportationSystem">
          <h3>Intelligent Transportation System</h3>
          <p class="contributor">Antoine Zimmermann</p>
          <label class="expand" for="uc22"></label>
          <input id="uc22" type="checkbox">
          <div>
          <p>Intelligent Transportation Systems (ITS) can be defined as the application of advanced information and communications technology to surface transportation in order to achieve enhanced safety and mobility while reducing the environmental impact of transportation. The addition of wireless communications offers a powerful and transformative opportunity to establish transportation connectivity that further enables cooperative systems and dynamic data exchange using a broad range of advanced systems and technologies. - See more at: <a href="http://www.its.dot.gov/standards_strategic_plan">http://www.its.dot.gov/standards_strategic_plan</a><p>
          <p>ITS do so by exploiting information from various origins, especially the Web. Several web sites, web services, datasets related to public transport services, traffic, road network structure, localized incidents, and so on have to be exploited in order to convey users with the best decisions, in real time. All of these information sources rely considerably on spatio-temporal data. The challenge is to model dependency in both space and time seamlessly and simultaneously so that the accuracy of analysis can be improved (for instance for regulation of multimodal transportation network) or the processing of aggregated information can be simplified (for instance for multimodal traveler information system). For such systems to work well in a pervasive way, it is also important that the system can easily discover relevant datasets/services based on the user current location.</p>
          <p>Consequently, such systems would greatly benefit from standardized formats, standard practices for publishing or making spatial data available online. A standard way of indicating time and time frames would also help correlate several temporally situated entities such as bus schedules, real time bus position, and traffic light durations.</p>
          <p>A specific type of ITS is Advanced Traveler Information System (ATIS) that computes an accurate travel duration. To do so, ATIS should be able to combine data following different spatio-temporal scales. These data could be related to the current or anticipated network traffic (the congestion level), the network topology (number of lines on the routes, presence of traffic lights, etc.), the presence of expected events (which can be static, like work on the road, or dynamic like demonstrations), the weather state (the presence of rain or mist on a part of the itinerary), and so on.</p>
          <p>ITSs can also be dedicated to the management of parking spots. For a driver, the choice of its parking spot is a multi-criteria decision process that takes into account static data given by the description of the infrastructure (whether the spot is private or public, reserved for disabled, etc.), dynamic data given by sensors (like traffic) and personal data (destination, budget).</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#DateTimeDuration"></a>, <a href="#MobileSensors"></a>, <a href="#MovingFeatures"></a>, <a href="#NominalObservations"></a>, <a href="#SpaceTimeMultiScale"></a>, <a href="#TemporalReferenceSystem"></a></p>
        </section>
        <section id="OptimizingEnergyConsumptionProductionSalesAndPurchasesInSmartGrids">
          <h3>Optimizing energy consumption, production, sales and purchases in Smart Grids</h3>
          <p class="contributor">Antoine Zimmermann</p>
          <label class="expand" for="uc23"></label>
          <input id="uc23" type="checkbox">
          <div>
            <p>In smart grids, energy management has to take into account the fact that any energy consummer may also be a producer (they are thus "prosumers"). This leads to new load balancing problems as well as new forms of economic exchanges regarding selling and buying energy. In order to take an informed decision on what amount of energy to buy from whom at what cost, or to sell, decision algorithms must use information that can be local (their own consumption and production), global (statistical data on seasonal household energy consumption), and possibly external to grid (meteorological data). In such context, reliance on Web data from several sources adds real value to the decision process.</p>
            <p>The kind of data that has to be considered are, for the most part, highly fluctuating: weather for assessing heating needs, stock exchange for pricing appropriately, current and future offer and demand, etc.</p>
            <p>There is a need for a temporal model that covers historical data for statistical analysis, short term timestamped sensed data, and data about future predictions.</p>
            <p>The need for spatio-temporal information is even increased if the smart grid is including electric vehicles that can serve as energy producers when they are not consuming electricity for recharging.</p>
          </div>
          <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a></p>
          <p class="relatedRequirements"><a href="#Linkability"></a>, ...</p>
        </section>
        <section id="Linked Data for Tax Assessment">
          <h3>Linked Data for Tax Assessment</h3>
          <p class="contributor">Luigi Selmi (via public-sdw-comments)</p>
          <label class="expand" for="uc24"></label>
          <input id="uc24" type="checkbox">
          <div>
            <p>Tax assessments are based on the comparison of what is due by a citizen in a year for her ownership of real estates in the area administered by a municipality and what has been paid. The tax amount is regulated by laws and based on many criteria like the size of the real estate, the area in which it is located, its type: house, office, farm, factory and others. Taxpayers can save money from the original due depending on the usage of the estate. A family that owns the house in which they live can save the entire amount. Many other regulations lighten in different ways the burden of the tax for other categories of taxpayers. Furthermore the situation about a taxpayer changes over the years in relation to her properties share and family status. Due to the many different situations met, an employee in charge of performing tax assessments on behalf of a municipality must collect many information before being able to assert with a good degree of confidence that a difference between the original amount and what has been paid is not justified and an advice has to be sent to the taxpayer starting a long and expensive process to recover the difference. Currently each single assessment requires the employee to collect information from different public administrations web sites, archives, registries, documents. Data scattered in so many silos and formats dramatically reduce employees productivity and assessment effectiveness at the point that it is not always clear whether the money recovered is worth the cost of the assessment. A Linked Data approach for sharing spatial and temporal data would certainly increase the productivity of the assessor.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="ImagesEGATimeSeriesOfAWaterCourse">
          <h3>Images, e.g. a Time series of a Water Course</h3>
          <p class="contributor">Kerry Taylor (on behalf of Jamie Baker, Australian Commonwealth Department of Communications)</p>
          <label class="expand" for="uc25"></label>
          <input id="uc25" type="checkbox">
          <div>
            <p>This use case is provided to extend three primary use cases already before the Working Group:
            <ul>
              <li><a href="#PublishingGeographicalData"></a></li>
              <li><a href="#ConsumingGeographicalDataInAWebApplication"></a></li>
              <li><a href="#PublishingGeospatialReferenceData"></a></li>
            </ul>
            More broadly the Commonwealth of Australia has developed a National Map web platform which is currently making available authoritative national datasets. There is a need to recognise that data can an image (e.g. an image-based tile set for example) and therefore in itself also create a time series-based resource (for example, the change in a water course over time which can be visualised as time series layers). Indeed both the ISO and OGC have recognised this in their standards. It is the Australian Government Department of Communication’s view, as the lead agency stewarding spatial data policy, that image-based resources should also be included in the consideration of this working group as it relates to geographic and spatial features geometries. Wheresoever possible the Commonwealth view is to maintain the highest applicability of a standard or best practice guide and not limit conformance options for data holdings (especially of public origin). This also applies to cadastral and other data at the state/territory level which could show the change in land parcel, development or other property and built environment features over time. In terms of our future cities, sensors and other data sources may also need linkage to image-based resources for citizen use. As such:
            <ol>
              <li>Image-based data needs to be recognised and discoverable as it too tells a story</li>
              <li>Time series data can be visual and therefore visualised as a data layer or an image in time or both</li>
              <li>Linking of data whether image-based or not should be discoverable and mix or match just as easily as data of a similar or dissimilar type</li>
              <li>Metadata conformance is crucial to support discoverability, interoperability and provide information on the nature of a data resource (e.g. Time series image or time series data)</li>
              <li>A challenge exists in maximising the interoperability of geographic and/or spatial data both above and below ground level. (An example may be subsurface water imaging data combined with sensor data).</li>
            </ol>
            This additional information supports a broader need for SSN, Coverage and Time considerations for the above three current use cases.
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#Discoverability"></a>, <a href="#GeoreferencedSensorData"></a>, <a href="#SpaceTimeMultiScale"></a>, <a href="#SensorDataTimeSeries"></a>, <a href="#3DSupport"></a></p>
        </section>
        <section id="DroughtsInGeologicalComplexEnvironmentsWhereGroundwaterIsImportant">
          <h3>Droughts in geological complex environments where groundwater is important</h3>
          <p class="contributor">Chris Little (on behalf of Andrew G Hughes, British Geological Survey)</p>
          <label class="expand" for="uc26"></label>
          <input id="uc26" type="checkbox">
          <div>
            <p>During the period 2011-2013, the UK faced an extraordinary drought only to be saved from a likely major crisis by very high spring and summer rainfall (CEH, 2012). Government asked questions such as “how much water is left in the tank?”, at which point managers and regulators realised that they didn’t know the answer with any certainty (EA, 2012). A National Drought Group of leading stakeholders was formed and led by the Chief Executive of the Environment Agency (EA) reporting to the Secretary of State for Environment, Food and Rural Affairs. The whole of the UK was affected, but the south-east most severely because of the lower rainfall and high water demand.</p>
            <p>When will London run out of water? How socially accepted is drought and associated water restrictions to the general public? When will water company groundwater sources begin to switch off? Questions like these are critical for drought management, but often the science is not sufficiently advanced to address them, and where it is, not fully integrated to satisfactorily answer them.</p>
            <p>The River Thames Basin is home to 13 Million people, considerable industry and valuable aquatic ecosystems all of which require the effective and sustainable management of the water environment in the basin to thrive. A thorough understanding of the hydrology of the basin is vital to underpin this management to ensure the best use of resources. This is particularly important given the twin pressures of increasing water consumption and climate change. The groundwater system of the Thames consists of around 12 aquifers most of which are not hydraulically connected, except via the River Thames and its tributaries. These aquifers are locally very important for water supply and their provision of base flow sustains the ecology of the river system in dry summer periods and droughts.</p>
            <p>To properly simulate the system then a good geological understanding has to be translated into a hydrogeological knowledge and then simulated. This is not a straight-forward task. The important elements of the system include: 3D geological understanding encapsulated into a geological model, dynamic model of the surface processes, groundwater and river systems along with a model of water supply (e.g. IRAS; Mastrosov et al., 2010). This will ultimately involve:
            <ul>
              <li>tatic data (updated as understanding increases)</li>
              <li>Data passed in a one way chain between models runs separately</li>
              <li>Dynamically linked models to investigate feedbacks between different parts of the system</li>
            </ul>
            The aim would be to develop an integrated system that can address the question “When will water company groundwater sources begin to switch off” or similar.</p>
            <h4>References</h4>
            <p>
            <ul>
              <li>CEH. (2012). Retrieved 7 Sep 2013, from <a href="www.ceh.ac.uk/data/nrfa/nhmp/other_reports/2012_Drought_Transformation.pdf">www.ceh.ac.uk/data/nrfa/nhmp/other_reports/2012_Drought_Transformation.pdf</a></li>
              <li>EA (2012). Review of the 2010-2012 drought and prospects for water resources in 2013. Environment Agency Report.</li>
              <li>Matrosov E.S., Harou, J.J. and Loucks D.P., 2010. A computationally efficient open-source water resource system simulator - Application to London and the Thames Basin. Environmental Modelling & Software. Volume 26, Issue 12, December 2011, Pages 1599–1610</li>
            </ul>
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#Linkability"></a>, <a href="#Provenance"></a>, <a href="#QualityMetadata"></a>, <a href="#NominalObservations"></a>, <a href="#3DSupport"></a>, <a href="#VirtualObservations"></a>, <a href="#DynamicSensorData"></a></p>
        </section>
        <section id="SoilDataApplications">
          <h3>Soil data applications</h3>
          <p class="contributor">Simon Cox (on behalf of Peter Wilson, Bruce Simons @ CSIRO)</p>
          <label class="expand" for="uc27"></label>
          <input id="uc27" type="checkbox">
          <div>
            <p><ol>
            <li>Farmer wants to know soil types and properties in an adjacent property which he is considering purchasing. ... the global soil community wants to be able to publish standardised soil site description/classification and soil analysis data which can then be collated (such as in the Harmonised World Soil Database) and used for modelling the spatial distribution of soil properties (digital soil mapping) (for example as part of the ISRIC 1kmSoilGirds or IUSS GlobalSoilMap projects). This would utilise our efforts with the SoilML (ISO28258) meta-model and the fully attributed implementable extension (currently ANZSoilML) to deliver the standardised soil data services.</li>
            <li>Compare similar soils and productivity responses to addition ... the IUSS GlobalSoilMap project wants to deliver high resolution estimates of functional soil properties as 90m raster data across the globe, constructed through bottom up, country delivery of standardised data. Our TERN Soil and Landscape Grid of Australia project has now developed the required data for Australia and we need to progress delivery as standardised services (using WMS,WFS and WCS) as a demonstrator of how to do this globally. The GlobalSoilMap project (maybe through the UN Global Soil Partnership, or via ISRIC the World Soil Data Centre) could develop a portal to allow discovery/display of all the contributing country data and to facilitate user (eg global climate or food security modellers) connection to the services from multiple sources.</li>
            <li>Agronomist needs observations of soil properties such as pH, Nitrogen, and soil-type and derive new properties using locally defined pedo-transfer functions ... Access observed and interpreted soil properties (by soil type and/or by spatial distribution) in a standard format that allows using algorithms/pedotransfer functions to use these properties to calculate additional interpreted soil properties.</li>
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#Discoverability"></a>, <a href="#ModelReuse"></a>, <a href="#ObservationAggregations"></a>, <a href="#QualityMetadata"></a>, <a href="#ReferenceExternalVocabularies"></a>, <a href="#SpaceTimeMultiScale"></a>, <a href="#VirtualObservations"></a></p>
        </section>
        <section id="BushfireResponseCoordinationCentre">
          <h3>Bushfire response coordination centre</h3>
          <p class="contributor">Simon Cox (on behalf of Paul Box, Simon Cox and Ryan Fraser @ CSIRO)</p>
          <label class="expand" for="uc28"></label>
          <input id="uc28" type="checkbox">
          <div>
            <p>
            This user story covers a number of interrelated use cases:
              <ul>
                <li>UC1 Search for place name</li>
                <li>UC2 Disambiguate place, based on type and provide</li>
                <li>UC3 Find the location of a place (centroid, representative location)– where is it?</li>
                <li>UC4 Find information about a place</li>
                <li>UC5 Find and use a suitable alternative geometric representations of a place – its shape, for a given scale and application</li>
                <li>UC6 Discover, access and use measurements relating to a place</li>
                <li>UC7.1 Discover related places - find synonyms</li>
                <li>UC7.2 Discover related places - topologically related places such as neighbouring, or containing regions</li>
              </ul>
            </p>
            <h4>User story</h4>
            <p>A bush-fire is underway in Blue Mountains NSW. An incident management team has been established, with an incident controller from NSW Fire and Rescue in charge, based in a coordination centre. She notices that the Twitter analytics feed has flagged a Tweet that mentions a fire in ‘Springwood’. The location of the Tweet shows on the incident map as being in the ‘Blue Mountains’ – (this location is a geocode of place name used in the Tweeter’s Profile). The watch officer enters ‘Springwood’ [uc1] in a multi-gazetteer index and gets 41 hits for Springwood in Australia. She zooms to the Blue Mountains and sees there are 13 places called Springwood. These results include a school, a number of rural properties, and an official suburb named Springwood [uc2] near which most of the other places are located. The officer selects the suburb name in the National Gazetteer, and the map zooms to the bounding box for the selected place [uc3]. The controller wants to find more detailed information about the place and clicks on its identifier (a URI for the place). The user is provided with information about:
            <ul>
              <li>identity of the place and data sets/collection to which it belongs [uc4]– e.g. the national gazetteer</li>
              <li>available geometries for the place [uc5]- e.g. a feature-service for a gazetteer data source, hosted by Geosciences Australia</li>
              <li>existence of links to additional sources of information about the place [uc6] – e.g. links to data about the suburb provided by the local government</li>
              <li>synonyms for the place – alternative identifiers used for the place [uc7.1] – e.g. identifiers used for suburbs in the Australian Statistical Geographic Standard (ASGS)</li>
              <li>related places [uc7.2] – e.g. a local government area that contains the suburb, or hydrological reporting units cover the suburb.
              <li>information about related places e.g:
                <ul>
                  <li>population profiles for the place codes using ASGS codes [uc7.1&6]</li>
                  <li>nearby sensors providing hydro/met data that are in the containing hydrological reporting unit [7.2 & 6]</li>
                </ul>
              </li>
            </ul>
            </p>
            <p>
            An official report of the fire location now also appears on the screen, from a fire service operator on the ground. With the fire location now confirmed, the priority is to identify the areas at risk, and assess community impact, locate possible evacuation centres and set in place evacuation plans.</p>
            <p>A fire spread model has been run using reported fire location. An impact analysis and evacuation plan is being developed. The predicted fire spread polygon is shown on the incident map. To assess affected population the analyst needs to find population geography and data. [uc5]</p>
            <p>The Springwood place landing page has a link to get information about the data source [uc4]. This is the national gazetteer, which provides bounding box geometries only. This is not accurate enough for her analysis. Returning to the graph of linked resources, the analysis determines that the gazetteer entry has a synonym in the ASGS [uc7.1]. She clicks on this and sees it’s the census geography for the same place (Springwood suburb) [uc4]. She finds the data source link which she discovers uses polygonal geometry and adds this as a service to her map.</p>
            <p>She is now able to see that Springwood suburb will be within the predicted fire polygon and will need to be evacuated. The analyst clicks linked information resources for Springwood (the synonym in the ASGS dataset) and a graph of related resources is displayed [uc 7.1, 7.2, 6]. This shows a link to a suburb profile based on the most recent national population and census data is available the analyst clicks on this and a query for predefined measurements (plus the place identifier) is passed to a census data cube service. The analyst visualises and saves the result set locally.</p>
            <p>The analyst also notices that information resources are connected to Springwood (in the gazetteer dataset) [uc 7.1, 7.2, 6]. These include a link to a containing local government area (LGA) and links to LGA emergency management resources on the website. This lists contact information and evacuation centres information which is used to inform development of the evacuation plan.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a></p>
          <p class="relatedRequirements"><a href="#Linkability"></a>, <a href="#SensorMetadata"></a>, <a href="#SpatialVagueness"></a>, ...</p>
        </section>
        <section id="ObservationsOnGeologicalSamples">
          <h3>Observations on geological samples</h3>
          <p class="contributor">Simon Cox</p>
          <label class="expand" for="uc29"></label>
          <input id="uc29" type="checkbox">
          <div>
            <p>Geological samples are retrieved from the field and then processed in the laboratory to determine various properties, including chemistry, mineralogy, age, and petrophysical properties like density, porosity, permeability.</p>
            <p>Samples obtained as part of economic activities, such as mineral exploration, are usually processed in commercial assay and chemistry labs. For QA/QC purposes, each batch of samples will have a number of control samples inserted, for which the concentration of particular chemical species are already known. For confidentiality reasons the location information associated with each sample is not provided to the lab, but must be re-attached during the interpretation phase. During processing, many derived samples will be generated by various physical and chemical procedures. In some cases the derived samples are strict sub-samples, whose intensive properties are intended to be the same as the parent. In other cases, the split is 'biased', with the derived sample intended to select a specific sub-sample, defined by a particular particle size, density, magnetic properties, etc. The link from the derived sample to the parent sample must be preserved, and the link from the parent to the location from which it was obtained also. In some cases the location is associated with another sampling artefact, such as a drill-hole or traverse or cruise, with the latter carrying the detailed location information.</p>
            <p>In a research context some samples have a particularly high-value, having been obtained by an expensive process (involving drilling or ships or spacecraft) or from a location that is hard to visit (remote, offshore, in space). These samples are sometimes sub-divided and distributed to multiple research teams or labs for different specialized observations. Each lab will run its own LIMS system, which will usually asign a local identifier for the sample. When the results of these observations are reported, it is necessary that observations from different labs can be correlated with each other, so that the complete picture around each sample can be assembled.</p>
            <p>These stories focus on sensing applications involving ex-situ sampling, where a location is visited and a specimen obtained using some sampling process, then transported to one or more laboratories where it is processed into one or more sub-samples and various observations made. Sample identity is usually key, and the relationships between samples, between samples and other artefacts of the sampling process, and also with other geographic features or locations. The sampling time and analysis and reporting time are all different.</p>
            <p>Similar process apply to botanical sampling, and to environmental sampling (water, air, dust).</p>
          </div>
          <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a></p>
          <p class="relatedRequirements"><a href="#DateTimeDuration"></a>, <a href="#DifferentTimeModels"></a>, <a href="#GeoreferencedSensorData"></a>, <a href="#Linkability"></a>, <a href="#ModelReuse"></a>, <a href="#Provenance"></a>, <a href="#ReferenceExternalVocabularies"></a>, <a href="#SensorMetadata"></a>, <a href="#ExSituSampling"></a>...</p>
        </section>
        <section id="SpatialSampling">
          <h3>Spatial Sampling</h3>
          <p class="contributor">Simon Cox</p>
          <label class="expand" for="uc30"></label>
          <input id="uc30" type="checkbox">
          <div>
            <p>Most observations are made on <em>samples</em> that are selected to be somehow representative of the feature of ultimate interest which is being characterized. The sample may be statistical, or related to accessibility, or may be of a proxy phenomenon which can be related to the property of ultimate interest.</p>
            <p>In environmental observations, certain spatial distributions are commonly used across multiple disciplines, such as
            <ul>
              <li>grids</li>
              <li>transects, cruises, flight-lines</li>
              <li>cross-sections</li>
              <li>physical sampling</li>
            </ul>
            These may be related to each other (samples taken along a drill-hole, stations on a traverse, shots along a seismic section) and the relationships provide a kind of 'topology' of sampling which assists access and processing. Sampling features may also be associated with other organizational structures, such as cruises, field trips, campaigns, projects, missions, orbits, deployments, platforms, which are used for discovery and for navigation within a datasets. Sampling strategies are often combined with an observational procedure or instrument to define a standard 'protocol' for observations. The protocol may be identified by name.</p>
            <i>Additional comment by Rachel Heaven:</i>
            <p>The locations within a spatial distribution may have a different degree of certainty with respect to each other than the positional certainty of the spatial distribution as a whole e.g. the ends of a sampling traverse may be known in a national or global coordinate reference system to +/-5m accuracy; soil samples may be taken along the traverse at every 1m +/-0.01m interval, or species sightings that need to be re-visited may be described in real world terms such as "half way up the burn on the left hand bank". Similarly, measurements taken down a drill hole are known accurately in down hole depth with respect to the drilling datum, but less accurately in true vertical depth and with respect to a national vertical datum. If the hole deviates from vertical, the absolute location will be even more uncertain.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#CRSDefinition"></a>, <a href="#GeoreferencedSensorData"></a>, <a href="#Linkability"></a>, <a href="#MobileSensors"></a>, <a href="#ModelReuse"></a>, <a href="#PositioningSystem"></a>, <a href="#SensorMetadata"></a>, <a href="#SpaceTimeMultiScale"></a>, <a href="#SpatialVagueness"></a>, <a href="#SamplingTopology"></a>, <a href="#UncertaintyInObservations"></a>, ...</p>
        </section>
        <section id="SelectHierarchicalGeographicalRegionsForUseInDataAnalysisOrVisualisation">
          <h3>Select hierarchical geographical regions for use in data analysis or visualisation</h3>
          <p class="contributor">Bill Roberts (based on needs arising from Swirrl's own work)</p>
          <label class="expand" for="uc31"></label>
          <input id="uc31" type="checkbox">
          <div>
            <p>Statistical data is frequently referenced against geographical regions. A common requirement is to select a collection of non-overlapping regions with complete coverage of a 'parent' region (a 'Mutually Exclusive Collectively Exhaustive' - MECE - set). This might be used for data aggregation: given the population statistics for all council areas in Scotland, calculate the population of Scotland.</p>
            <p>Or it might be for data visualisation: retrieve data on average house prices for all parliamentary constituencies in the UK, then combine this with polygons of the constituency boundaries and use it to draw a choropleth map.</p>
            <p>Although geographical data frequently includes 'contains' or 'within' relationships between larger and smaller areas, this is not sufficient for the above use cases. A larger area can be broken down into smaller areas in a variety of ways. Sometimes a combination of 'contains' relationships and knowledge of the 'type' of region can be enough: it may allow separating out a particular level in a geographical hierarchy. But that doesn't allow for cases where regions of a particular type don't have full coverage of the parent. An example is 'parishes' in England. The collection of all current parishes is non-overlapping, but it is not exhaustive. Some locations are not in any parish.</p>
            <p>The variation of administrative, statistical and political geography over time is also an issue. A particular division of a region into sub-regions may be valid only for a specific period. For example, council boundaries change from time to time. At any given time, there is a MECE set of council boundaries in a region, but the boundaries change occasionally, so if analysing data on English councils from 2014, a different set of areas is required than would be needed for say 2012. 2012 might involve areas A,B,C,D,E,F whereas 2014 requires A,B,C,D,G,H. A similar issue arises when dividing Europe up into countries for example.</p>
            <p>These are common problems and there are probably many separate solutions already in active use. It would be useful however to have a standardised vocabulary to represent these kind of relationships, which would increase the interoperability of data analysis tools.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a></p>
          <p class="relatedRequirements"><a href="#DateTimeDuration"></a>, <a href="#ValidTime"></a></p>
        </section>
        <section id="SatelliteDataProcessing">
          <h3>Satellite data processing</h3>
          <p class="contributor">Kerry Taylor (informed by Matt Paget and Juan Guerschman, CSIRO)</p>
          <label class="expand" for="uc32"></label>
          <input id="uc32" type="checkbox">
          <div>
            <p><em>Vegetation fractional cover</em> is a key metric for monitoring land management, both in pastoral and agricultural settings. The aim is to estimate the fractions of photosynthetic and non-photosynthetic vegetation and the remaining fraction of bare soil. Fractional cover is computed from both Landsat and MODIS satellite surface reflectance products but calibration and validation via ground-based observations is also needed.</p>
            <p>The method for computing fractional cover was developed by comparing geo-aligned Landsat sensor and two MODIS-derived surface reflectance products. Scaling issues associated with different sensors and spatial resolutions were addressed, along with locally-measured effects of soil colour and soil moisture.</p>
            <p>
            Source Data:
            <ol>
              <li>Data from the TM (Landsat 5) and ETM+ (Landsat 7) sensors were downloaded from the United States Geological Survey (USGS) and corrected for atmosphere, topographic and bi-directional surface reflectance effects, standardised to a nadir view (i.e., satellite zenith angle is zero) and a solar zenith angle of 45°)</li>
              <li>The MODIS 16-Day Nadir BRDF-Adjusted Reflectance product (MCD43A4) provides surface reflectance data as if they were taken from the nadir view and uses the solar angle calculated at local solar noon (Schaaf et al., 2002). MCD43A4 data were obtained from the Land Processes Distributed Active Archive Center (LPDAAC). These data were resampled to a geographic coordinate system.</li>
              <li>The MODIS surface reflectance products from the Terra satellite (MOD09) provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering and absorption (Vermote et al, 2011; Vermote & Kotchenova, 2008). The 8-day composite (MOD09A1) selects the best possible observation from an 8-day window, selected on the basis of high observation coverage, low viewing angle, cloud free and low aerosol loading, with a spatial resolution of 500 metres and seven spectral bands. The MOD09A1 surface reflectance data used here were subject to the same geometric processing as the MCD43A4 data.</li>
              <li>Field measurements of fractional cover were obtained at 913 sites across Australia (ABARES, 2013). Exactly 78 of those sites were sampled repeatedly, resulting in a total of 127 observations (a measurement taken at a given site on a specific date). The field observations did not systematically record soil colour or soil moisture. Recent observations include soil colour (Munsell Soil Color Charts, 1994), yet soil moisture is only subjectively measured (i.e., wet or dry). To derive these two soil properties consistently and objectively for the entire series we used information derived from other sources.</li>
            </ol>
            <p>As a result, a combined product is proposed which gives flexibility to use MODIS-derived estimates when large areas and high temporal repetition is desired, and Landsat-derived estimates when high spatial resolution is essential and/or when data prior to 2000 is needed. The algorithms needed for implementing a fractional cover product based on a blended Landsat-MODIS product are given <a href="#refGuerschman">[1]</a>.</p>
            <p>Now, this fractional cover coverage product over Australia is computed monthly and <a href="http://www.auscover.org.au/xwiki/bin/view/Product+pages/FC+Composites+MODIS+OEH">distributed by the NSW government</a>, where it is used for their <a href="http://www.environment.nsw.gov.au/dustwatch">Dustwatch program</a> amongst other things. The Dustwatch program publishes monthly (PDF) reports of wind-related erosion and groundcover change.</p>
            <p><b id="refGuerschman">[1]</b> <a href="http://www.sciencedirect.com/science/article/pii/S0034425715000395">Guerschman et al, "Assessing the effects of site heterogeneity and soil properties when unmixing photosynthetic vegetation, non-photosynthetic vegetation and bare soil fractions from Landsat and MODIS data", Remote Sensing of Environment, to appear 2015.</a>(Note that this paper provides several references to similar approaches to using multispectral coverages to determine vegetation)</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#CRSDefinition"></a>, <a href="#GeoreferencedSensorData"></a>, <a href="#MobileSensors"></a>, <a href="#PositioningSystem"></a>, <a href="#Provenance"></a>, <a href="#SensorMetadata"></a>, <a href="#CitizensAsSensors"></a>, <a href="#VirtualObservations"></a>, <a href="#SensingProcedure"></a>, ...</p>
        </section>
        <section id="MarineObservationsEMII">
          <h3>Marine observations - eMII</h3>
          <p class="contributor">Simon Cox (on behalf of <a href="http://imos.org.au/emii.html">IMOS eMII</a>)</p>
          <label class="expand" for="uc33"></label>
          <input id="uc33" type="checkbox">
          <div>
            <section>
            <h4>Water column observations</h4>
            <p>I am a modeller and I want to find, filter and extract water column data that has been collected by profiling instruments (e.g. CTD, XBT, ARGO Floats, CTD’s mounted on animals) so that I can prime my models. I want to easily be able to discover these data either by nominating the collection device type, or by nominating data parameters of interest. Once I can see which datasets meet my broad discovery criteria, and whilst still in the Portal, I want to be able to filter out data that is not of interest (e.g. those data outside of my region of interest, those not covering my features of interest, data which is unqualified, data below a certain depth and data from institutions I don’t trust). I want to extract these data in a harmonised format (i.e. receive a single file of aggregated data expressed using common data fields, or in multiple files where each file has a similar syntactic and semantic encoding). I don’t want to have to spend time transforming datasets with differing formats, nor guess which data fields in datasets from different sources are semantically covering the same information. I need to know what each field in the downloaded data represents.</p>
            </section>
            <section>
            <h4>Reconfiguring data ingestion process</h4>
            <p>I am an eMII Project Officer. I spend my day pulling data from partner services and transforming it so that it can be published through the 1-2-3 Portal. Just when I think I have tweaked all of the systems I need to in order to successfully ingest and publish provider data, the provider changes his/her data format, schema syntax or semantics. I then have to re-write or re-configure systems to obtain any new data. This happens very frequently. Even data providers who supply me with data from the same instruments use different data encodings and formats so I have to create individualised database tables to manage their incoming data. I would like data providers to agree on common schema for expressing similar data types and in collaboration develop some ‘governance’ rules surrounding data publication to the Portal to reduce the time I spend on repetitive (and often unnecessary) tasks.</p>
            </section>
            <section>
            <h4>Observations along profiles</h4>
            <p>I am an eMII Project Officer and I manage multiple profile type datasets (e.g.: Argo profile, seals profile, XBT profile …). I want to be able to assess the quality of the data provided by partners before inclusion into the IMOS database and making it available through the IMOS portal. I want to set up a system whereby every new profile will be compared with existing profiles available in the IMOS database. The incoming profile will have to conform to a standard format so that it is relatively easy to implement and develop different set of rules to enable comparison with existing profiles. The system will send me an alert if one or multiple profiles failed some tests. Then I will be able to follow up more quickly with the corresponding partners to check if an error occurs during the processing of the data or if actually the data is correct. In the end, this process will enable an increase of the quality of the data provided to the end user.</p>
            </section>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#Discoverability"></a>, <a href="#MobileSensors"></a>, <a href="#ModelReuse"></a>, <a href="#ObservationAggregations"></a>, <a href="#QualityMetadata"></a>, <a href="#SensorMetadata"></a>, <a href="#3DSupport"></a>, <a href="#SamplingTopology"></a></p>
        </section>
        <section id="MarineObservationsDataProviders">
          <h3>Marine observations - data providers</h3>
          <p class="contributor">Simon Cox (on behalf of <a href="http://imos.org.au/emii.html">IMOS eMII</a>)</p>
          <label class="expand" for="uc34"></label>
          <input id="uc34" type="checkbox">
          <div>
            <section>
            <h4>Atlas of Living Australia (ALA)</h4>
            <p>The ALA would like to integrate their data into the AODN. The ALA serves a range of web services including WMS and corresponding ISO19115/MCP metadata. The ALA's use case is unusual in that it has tens of thousands of WMS layers and metadata records. This data cannot be added to version 2 of the AODN portal because it is too large to be harvested into the menu tree. ALA will need to be integrated with the 123 portal. Dave Martin's team has created a proof of concept integration. There would be a single metadata record for ALA, which will allow it to be discovered in Step 1 of the portal. After proceeding to Step 2 the user would see something like <a href="http://bl.ocks.org/nickdos/raw/119e3c16edeced2a9355/">this mockup</a>. 
            </p>
            </section>
            <section>
            <h4>Reef Life Survey (RLS)</h4>
            <p>RLS have visited 2500+ coral and rocky reef sites and have conducted approx 6000 surveys across those sites. Each survey is conducted at a nominal ‘site’.
              <section>
              <h5>Methods 1 & 2</h5>
              <p>During a survey observations are recorded of each of (1) vertebrate species abundance and biomass and (2) invertebrate species abundance.<p>
              </section>
              <section>
              <h5>Method 3</h5>
              <p>During a survey downward looking photographs are taken. The photographs are sequenced 1-20 for each site and are not geolocated. Subsequently, the photographs are scored at 5 points within each image. Each point is scored into one of 36 categories. Parameters are date, depth, resolution, major category, minor category, numerical value.</p>
              </section>
              <section>
              <h5>User Story 1</h5>
              <p>I’m interested in ecosystems, reef assemblages and inter-species interactions. Show me what vertebrate and invertebrate species were found at this site (and any corresponding location/depth/habitat information).</p>
              <p>What I want to see:
                <ul>
                  <li>By site, all vertebrate species abundance and biomass values (for each survey?)</li>
                  <li>By site, all invertebrate abundance values (for each survey?)</li>
                </ul>
              </p>-
              </section>
              <section>
              <h5>User Story 2</h5>
              <p>I have a large-scale question to ask about a particular species, for example, I am interested in broad distribution patterns of lobsters, plankton dispersal and settling rates. Show me all of the sites that were surveyed and the presence/absence of a particular species at each of those sites.</p>
              <p>What I want to see:
                <ul>
                  <li>Across all sites that have been surveyed by RLS, the latitude, longitude, depth and presence/absence of a particular vertebrate or invertebrate species (no time component)</li>
                  <li>A time selector that shows changing or stable presence/absence values for repeat surveys at the same site</li>
                </ul>
              </p>
              </section>
            </section>
            <section>
            <h4>Institute for Marine and Antarctic Studies (IMAS)</h4>
            <p>The IMAS use case includes a number of data collections. The main requirements is a mechanism to easily install the necessary applications. Ideally the AODN will host the applications (GeoNetwork, Geoserver etc) in the NeCTAR Cloud. This cloud based infrastructure will be manged by the AODN, but IMAS will have administrator accounts on each application and will be responsible for data content.</p>
            </section>
          </div>
          <p class="relatedDeliverables"><a href="#SSN"></a></p>
          <p class="relatedRequirements"><a href="#GeoreferencedSensorData"></a>, <a href="#NominalObservations"></a>, <a href="#CitizensAsSensors"></a>, <a href="#3DSupport"></a>, <a href="#UncertaintyInObservations"></a>, ...</p>
        </section>
        <section id="MarineObservationsDataConsumers">
          <h3>Marine observations - data consumers</h3>
          <p class="contributor">Simon Cox (on behalf of <a href="http://imos.org.au/emii.html">IMOS eMII</a>)</p>
          <label class="expand" for="uc35"></label>
          <input id="uc35" type="checkbox">
          <div>
            <section>
              <h4>Download Temperature and Velocity Data from NSW Moorings</h4>
              <p>The user would like to download temperature and velocity data from NSW moorings without downloading large numbers of NetCDF files, and without needing many clicks.</p><p>(Based on feedback from Robin Robertson)</p>
            </section>
            <section>
              <h4>Download Glider Data</h4>
              <p>The user would like an easy way to download the calibrated glider data. The user does not want the data delivered manually via drop box, or to face the difficulty of downloading NetCDF files in the way they are currently provided.</p><p>(Based on feedback from Robin Robertson)</p>
            </section>
            <section>
              <h4>Download ANMN Timor South moorings data</h4>
              <p>The user would like to download the ANMN Timor South moorings data - without needing 160 clicks.</p><p>(Based on feedback from Rebecca Cowley)</p>
            </section>
            <section>
              <h4>Download XBT data</h4>
              <p>The user would like to download XBT data from the portal. Not just the metadata - but the actual data.</p><p>(Based on feedback from Rebecca Cowley)</p>
            </section>
            <section>
              <h4>Download NRS data</h4><p>The user would like to be able to download NRS moorings data.</p><p>(Based on feedback by Peter Thompson)</p>
            </section>
            <section>
              <h4>Understandable by scientists from other fields</h4>
              <p>The user would like to be able to understand the portal even though she is from another field (e.g. genomics).</p><p>(Based on feedback from Levente Bodrossy)</p>
            </section>
            <section>
              <h4>Filter moorings data by deployment and instrument type</h4><p>The user would like to be able to filter moorings data by deployment and instrument type.</p><p>(Based on feedback from Craig Steinberg)</p>
            </section>
            <section>
              <h4>Download data as CSV</h4><p>The user would like to download sea surface temperature from the Bass Straight as a CSV file - not NetCDF</p><p>(Based on feedback from Andre Chiaradia)</p>
            </section>
            <section>
              <h4>Argo float data in a bounding box in the Southern Ocean.</h4><p>The user would like to download argo data from a particular region in the Southern Ocean.</p><p>(Based on feedback from Esmee)</p>
            </section>
            <p>Also see <a href="https://sites.google.com/site/aodntag/working-groups/use-cases/data-consumers">additional stories in un-edited emails</a></p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="BuildingInformationManagementAndDataSharing">
          <h3>Building information management and data sharing</h3>
          <p class="contributor"> Linda van den Brink (with thanks to Henk Schaap - Gobar)</p>
          <label class="expand" for="uc36"></label>
          <input id="uc36" type="checkbox">
          <div>
            <p>The Dutch organization <a href="http://www.rws.nl/en">Rijkswaterstaat</a> is responsible for the practical execution of the public works and water management, including the construction and maintenance of waterways and roads, and flood protection and prevention in the Netherlands. The following is a use case about sharing Rijkswaterstaat information to support building processes.</p>
            <p>A part of a highway is in need of a new tarmac layer. This involves a lot of information sharing between the contractor (Rijkswaterstaat), the organization responsible for organizing the project and the organization responsible for carrying out the maintenance work. Building Information Management (BIM) is used for this and the data is published via a webserver.</p>
            <p>The information being exchanged is asset management information, i.e. the location of the roads, tunnels, bridges, aquaducts, railway lines, surrounding terrain and waterbodies involved (geometric information). In addition, non-spatial information is important, like the layers of material the road consists of, when it was last maintained etc. The spatial information is not only shared as 2D geometries: (detailed) 3D information is also used in the building process. The area involved contains about 9.000 relevant physical objects (about 100 different object types) and about 2.000 spatial objects that relate to the traffic network, about which information is exchanged.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"><a href="#3DSupport"></a></p>
        </section>
        <section id="LandsatDataServices">
          <h3>Landsat data services</h3>
          <p class="contributor">Kerry Taylor (on behalf of Aaron Sedgmen of Geoscience Australia)</p>
          <label class="expand" for="uc37"></label>
          <input id="uc37" type="checkbox">
          <div>
            <p>Geoscience Australia (GA) maintains an archive of Landsat 5, 7 and 8 satellite imagery over the Australian continent from 1986 to present. The Australian Reflectance Grid 25 (ARG25) dataset produced from the Landsat archive is a collection of approximately 184,000 individual Landsat 5 and Landsat 7 scenes processed to the ARG25 specification. The ARG25 data are available to the public as file downloads and OGC web services. The ARG25 collection can be searched using an OGC Catalogue Service (CSW) containing ISO 19115 metadata for each scene. Note that the ARG25 data services are expected to be superseded by the Australian Geoscience Data Cube when it becomes publically available.</p>
            <p>The ARG25 data services were promoted for use at the 2013 and 2014 Australian GovHack events, a competition aimed at mainstream (i.e. largely non geoscience/geospatial specialist) web and application developers, to mashup, reuse, and remix open government data. The predominant use case for the ARG25 data at GovHack has been to perform spatiotemporal searches on the catalogue for an area of interest, retrieve and subset/stitch scenes from the web services, and provide an animated time sequence of the imagery to allow users to visualise changes in land cover over time, e.g. “show me how my town has grown over the last 10 years”.</p>
            <p>The relative complexity and richness of the OGC/ISO web service APIs and data exchange formats presented a barrier to developers who were accustomed to lighter weight APIs and formats optimised for rapid integration and mashing up of data in mobile and browser based applications. As a result, uptake of the ARG25 data at GovHack was less than hoped for, and we see this as indicative of the mainstream web app development community in the real world.</p>
            <p>GA has had much success with OGC and ISO standards in the sharing of data with government, research and industry partners and clients who are power users of spatial data and savvy in the standards. The less traditional users who are not spatial data specialists are less likely to access GA’s data delivered using OGC and ISO standards, and this is a section of the user community that can potentially apply the data to highly innovative and entrepreneurial uses.</p>
            <p>GA does use proprietary and quasi-standard light weight data exchange formats (e.g. JSON) and web APIs (e.g. ESRI RESTful API) for delivering some geospatial data, although, in accordance with government policy, it is GA’s preference to adopt standards when possible to maximise interoperability.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#DateTimeDuration"></a>, <a href="#Discoverability"></a>, <a href="#TimeSeries"></a></p>
        </section>
        <section id="MetadataAndSearchGranularity">
          <h3>Metadata and Search Granularity</h3>
          <p class="contributor">Kerry Taylor (on behalf of Aaron Sedgmen of Geoscience Australia)</p>
          <label class="expand" for="uc38"></label>
          <input id="uc38" type="checkbox">
          <div>
            <p>Geoscience Australia (GA) collects and curates Australian national geoscience and geographic data sets, for use by government, industry and the community. Following is a typical requirement of a user of GA data - “A mineral exploration company is collating published geological data for their mining lease. They are particularly interested in sample locations where gold ppm values are above 0.1ppm, occurring in greenstone, located on or near a fault line, and aged around 2.6 Ga”.<p>
            <p>Users are able to perform structured searches for GA datasets at the collection level using catalogues of ISO 19115 metadata. The collection level metadata provides users with download links to the packaged datasets, and in limited instances, links for accessing the data via web services and/or applications that provide visualisation and GIS analysis capability.</p>
            <p>To perform fine grained searches within the dataset, such as feature level searches (e.g. show me sample locations in the OZCHEM database with gold ppm > 0.1), users must download the packaged datasets to their local environment and use their own tools to search through the data. Web services providing data access, e.g. WFS, and web applications with GIS capability served by GA, e.g. the Rock Properties Explorer app, can provide some capability for searching within data collections.</p>
            <p>Usability of search and discovery systems would be enhanced by having standards that define the line between spatial data and metadata in the context of searches, and standard methodologies for searching across collection level and feature level data.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a></p>
          <p class="relatedRequirements"><a href="#DifferentTimeModels"></a>, <a href="#NominalTemporalReferences"></a>, <a href="#TemporalMultiScale"></a>, <a href="#TemporalReferenceSystem"></a></p>
        </section>
        <section id="CrowdSourcedEarthquakeObservationInformation">
          <h3>Crowd sourced earthquake observation information</h3>
          <p class="contributor">Kerry Taylor (on behalf of Aaron Sedgmen of Geoscience Australia)</p>
          <label class="expand" for="uc39"></label>
          <input id="uc39" type="checkbox">
          <div>
            <p>Geoscience Australia (GA) collects earthquake observation information from the general public to improve its knowledge base of the impact of earthquakes across the Australian continent. An online HTML form is available on the GA website for members of the public to report their experiences of earthquake events. Information collected includes the person’s location (both geographic and within a building), time of event, perception of intensity and observed effects on the built environment. The information provided by the public is rated against the Modified Mercalli Intensity (MMI) Scale and is used to improve the accuracy of shake maps for earthquake prone regions of the country. This feeds into GA’s understanding of exposure of the Australian built environment to natural disaster, and is used for disaster mitigation purposes including the determination of minimum building codes for various regions of the country.</p>
            <p>There is potential for GA to improve the efficiency by which it obtains earthquake observation information from the general public by leveraging popular social media services (such as Twitter), and adopting common standards and best practices for collecting crowd sourced information.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a></p>
          <p class="relatedRequirements"><a href="#PositioningSystem"></a>, <a href="#NominalObservations"></a>, <a href="#MultilingualSupport"></a>, <a href="#CitizensAsSensors"></a>, <a href="#SpatialVagueness"></a>, ...</p>
        </section>
        <section id="TCGAMicroscopyImaging">
          <h3>TCGA / Microscopy Imaging</h3>
          <p class="contributor">Erich Bremer</p>
          <label class="expand" for="uc40"></label>
          <input id="uc40" type="checkbox">
          <div>
            <p>Studying the morphology of disease at the cellular and sub-cellular levels using high resolution tissue images is extremely important to help understand the nature of various cancers. <a href="http://cancergenome.nih.gov/">The Cancer Genome Atlas (TCGA)</a> contains over 32,000 de-identified whole-slide microscopy images (WSI) of over two dozen cancer types. These images can contain between 100K-1M nuclei each. Biomedical informatics researcher have developed (and continue to develop) software to automatically segment nuclei for study. The spatial features of each nucleus and groups of nuclei as it relates to other nuclei combined with other linked data such as other morphological features (crypts, ducts, etc.) and/or patient lab results are used in analyzing and categorizing tissues and patients into groups and in comparing such groupings to understand disease mechanisms in a particular cancer type as well as across cancer types.<p>
            <p>Representing nuclear segmentations is often done with binary masks or through polygon representations (e.g., the use of Well Known Text (WKT) representations) and also by leveraging work from the Geospatial community. However, in the case of nuclear segmentations, coordinate systems are 2D & 3D Cartesian based. Although the majority of work is this area is 2D-based, a growing segment of microscopy is also 3D-based as the technology develops and become more sophisticated. As living tissue can change over time through growth, infection, cancer, damage, etc, (as well as its associated organism’s various properties) it is important that spatial locations of features such as nuclear segmentation be also represented in a temporal aspect for proper comparisons.</p>
            <p>Samples of TCGA WSI data can be viewed at: <a href="http://cancer.digitalslidearchive.net">http://cancer.digitalslidearchive.net</a></p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#3DSupport"></a>, ...</p>
        </section>
        <section id="CropYieldEstimationUsingMultipleSatellites">
          <h3>Crop Yield Estimation using multiple satellites</h3>
          <p class="contributor">Kerry Taylor with Zheng-Shu Zhou, CSIRO</p>
          <label class="expand" for="uc41"></label>
          <input id="uc41" type="checkbox">
          <div>
            <p>Space-borne Synthetic Aperture Radar (SAR) observations are coming on line rapidly over the next few years. SAR signals are represented in 2D space but can be processed to point observations in 3D space, or to 3D triangulated surfaces using polarimetric and phase information. A compelling use case for SAR data is crop classification, i.e., identification of cereal crops (wheat, barley, rice etc.), through analysis of the radar backscatters and polarisations over the variable-height surface and volume of the crop.</p>
            <p>Multispectral (e.g. Landsat or MODIS) satellite imagery has been widely used to estimate vegetation cover and growth rates. It seems that combining SAR derived crop-type observations with Landsat-derived vegetation estimations could be used to estimate crop yields throughout the growth cycle. In principle, access to such data is open, but in practice it is difficult to get hold of and difficult to process for anyone other than well-connected scientists in developed nations. How could this data be opened up to a bigger community to help solve this problem, perhaps aided by reference to local knowledge?</p>
            <p>We might expect that this will be used to assist in logistics and market planning in developed countries, and for food security in developing and war-torn nations.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a>, <a href="#3DSupport"></a>, <a href="#VirtualObservations"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="GeospatialExtensionsToDomainIndependentMetadataSchemas">
          <h3>Geospatial extensions to domain-independent metadata schemas</h3>
          <p class="contributor">Andrea Perego (<a href="https://ec.europa.eu/jrc/">European Commission - Joint Research Centre</a>)</p>
          <label class="expand" for="uc42"></label>
          <input id="uc42" type="checkbox">
          <div>
            <p><a href="https://joinup.ec.europa.eu/asset/dcat_application_profile/">DCAT-AP (DCAT application profile for data portals in Europe)</a> is a metadata interchange format, based on and compliant with the <a href="http://www.w3.org/TR/vocab-dcat">W3C Data Catalog vocabulary (DCAT)</a>, defining a minimum set of metadata elements to ensure cross-domain and cross-border interoperability across European data portals.</p>
            <p>Work is under-way for a development of an extension aiming at defining a DCAT-AP compliant representation of geospatial metadata, referred to as <a href="https://joinup.ec.europa.eu/asset/dcat_application_profile/#Geo-DCAT-AP">GeoDCAT-AP</a>.</p>
            <p>GeoDCAT-AP will build on preliminary work concerning the <a href="https://ies-svn.jrc.ec.europa.eu/projects/metadata/wiki/INSPIRE_profile_of_DCAT-AP_-_Reference">alignment of INSPIRE metadata with DCAT-AP (referred to as INSPIRE+DCAT-AP)</a>. The objective is to consolidate this work, and to extend it in order to cover the set of metadata elements corresponding to the union of the <a href="http://eur-lex.europa.eu/eli/reg/com/2008/1205#d1e38-14-1">INSPIRE metadata schema</a> and the core profile of ISO 19115.</p>
            <p>Methodologically, GeoDCAT-AP will be designed based on the following requirements:
            <ol>
              <li>agree on mappings with metadata elements available in DCAT-AP (e.g., title, abstract, licence, distributions)</li>
              <li>define alignment with elements not available in DCAT-AP, by using, whenever possible, popular RDF vocabularies</li>
            </ol>
            The requirement for point (2) is to identify an RDF representation of elements missing in DCAT-AP that can be re-used, if relevant, in other domains. E.g., elements concerning data quality (e.g., conformity, topological consistency) and granularity (e.g., spatial / temporal resolution), two notions not supported in DCAT-AP (nor in DCAT). This implies that, in many cases, there may be the need of relaxing the ISO 19115 specification whenever it may be a barrier to re-use.</p>
            <p>Another key design principle is that GeoDCAT-AP is not meant to be a replacement of ISO 19115 / 19139, but an alternative representation, built on a set of harmonised mappings. For this reason, the principle is that any ISO 19115-conformant metadata record could be transformed into a GeoDCAT-AP one, but the opposite is not a requirement.</p>
            <p>Issues to be addressed include the following:
            <ul>
              <li>Recommendations on the use of HTTP URIs for geospatial data and metadata</li>
              <li>Recommendations on the representation of geometries, and for the specification of bounding boxes, centroids, etc.</li>
              <li>Recommendations for the specification of spatial and temporal reference systems</li>
              <li>Recommendations for the specification of spatial and temporal resolution</li>
            </ul>
            </p><p>Related use cases:
            <ul>
              <li><a href="#CombiningSpatialRDFDataForIntegratedQueryingInATriplestore"></a></li>
              <li><a href="#PublishingGeospatialReferenceData"></a></li>
              <li><a href="#ImprovingDiscoveryOfSpatialDataOnTheWeb"></a></li>
            </ul>
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"><a href="#BoundingBoxCentroid"></a></p>
        </section>
        <section id="ImprovingDiscoveryOfSpatialDataOnTheWeb">
          <h3>Improving discovery of spatial data on the Web</h3>
          <p class="contributor">Andrea Perego (<a href="https://ec.europa.eu/jrc/">European Commission - Joint Research Centre</a>)</p>
          <label class="expand" for="uc43"></label>
          <input id="uc43" type="checkbox">
          <div>
            <p><i>Use case based on <a href="http://inspire.ec.europa.eu/events/conferences/inspire_2014/pdfs/19.06_4_11.00_Adam_Iwaniak.pdf">work presented at INSPIRE 2014</a> by Adam Iwaniak (Wroclaw University of Environmental and Life Sciences, Poland)</i><p>
            <p>Geoportals offer effective discovery functionalities for specialists. However, as in most data portals, using basic free text search is usually far from being a satisfactory experience. Actually, users (both non-experts and specialists), when searching for data, are frequently making use of popular search engines as a first step to get to the data they are looking for.</p>
            <p>Improving free text search in (geo)data portals is unlikely to address this issue. Moreover, it would not help users who do not know in which portal(s) the relevant data are available. Users will keep on using in any case search engines for this purpose.</p>
            <p>An option would be optimising geoportals for Web discovery, by implementing consistently SEO (Search Engine Optimisation) techniques. The advantages include (but are not limited to) the following:
            <ul>
            <li>Increase visibility of spatial data - as well as of the geoportals giving access to them.</li>
            <li>Enabling queries not limited to free free text fields (e.g., dataset title and description), but concerning also coordinates, spatial / temporal resolution, etc.</li>
            <li>Enabling users to find the data better satisfying their requirements (in terms of spatial and temporal coverage, granularity, formats, access and licensing conditions, etc.)</li>
            </ul>
            The SDW WG BPs may contribute to this by recommending best practices for publishing geospatial metadata on the Web. For example, by proposing standard serialisations of geospatial metadata in formats and vocabularies used by search engines to index Web resources - e.g., RDFa, Microdata, Microformats.</p>
            </p>
            <p>Related use cases:
              <ul>
                <li><a href="#ConsumingGeographicalDataInAWebApplication"></a></li>
                <li><a href="#GeospatialExtensionsToDomainIndependentMetadataSchemas"></a></li>
              </ul>
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="INSPIREComplianceUsingWebStandards">
          <h3>INSPIRE compliance using web standards</h3>
          <p class="contributor">Erwin Folmer, <a href="http://www.kadaster.nl/web/english.htm">Dutch Cadastre</a> (via public-sdw-comments@w3.org)</p>
          <label class="expand" for="uc44"></label>
          <input id="uc44" type="checkbox">
          <div>
            <p>The European INSPIRE directive leads to the availability of many datasets with geographical aspects. Unfortunately the burden for data providers to comply with INSPIRE is high, which leads to the potential danger that the means (INSPIRE) becomes more important than the end (to have interoperable data). For many data providers the sole purpose is to state that they are INSPIRE compliant. This limited but understandable approach of data providers results in potential users being overlooked. Implementations of more user-friendly web-related solutions will be very difficult and limited in the next few years, unless we find a (documented, proven and accepted) way to comply with INSPIRE by using web standards (Linked Data).</p>
            <p>The Dutch Cadastre is a major provider of INSPIRE data in the Netherlands. It also maintains the portal <a href="https://www.pdok.nl/en/node">PDOK</a>, a central facility for making INSPIRE-compliant geographical data available in the Netherlands.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="EventlikeGeographicFeatures">
          <h3>Event-like geographic features</h3>
          <p class="contributor">Karl Grossner, Stanford Libraries</p>
          <label class="expand" for="uc45"></label>
          <input id="uc45" type="checkbox">
          <div>
            <p>Events are geographic phenomena. They comprise activity associated with particular locations on the earth surface, and their participants' locations and attributes over time are integral to their analysis as well as their indexing in information systems. Event participants may be human and agentive or not -including for example objects present at or resulting from activity, or natural phenomena like hurricanes or earthquakes.</p>
            <p>In addition to class or type, and the nature of their participants, essential descriptors for events include their static or dynamic location(s) and temporal extents, described with spatial and temporal reference systems. Location may be static or dynamic. Static events routinely modeled include crime, mortality, battles, performances, etc. Temporal extents may be modeled as instants or intervals, in cases aggregated as "multi-instants" or "multi-intervals."</p>
            <p>Although it is inherently difficult to model dynamic phenomena, there are many compelling reasons to do so. They can be conceived variously, as processes modeled as sequences of discrete events or as functions. Examples include: trajectories of people in commercial activity, journeys, battles, and biographical "life-paths."</p>
            <p>From a spatial perspective, many places are essentially dynamic and modeling these is a core challenge in historical and cultural heritage applications. The size and shape of political entities changes over time; they grow, shrink, split, merge, disappear, reappear, etc. The point being their spatial extent is directly bound to time. Historical periods are considered as 'place-at-period' - for example there is not a simple "Bronze Age" period, rather "Bronze Age Britain" and "Bronze Age Southern Levant."</p>
            <p>Taken together these share a requirement to consider space and time together.</p>
            <p>There is ongoing work in several research communities to arrive at better general models for representing and computing over such spatial-temporal and dynamic phenomena. One approach aims at 4-dimensional model of space-time (e.g. <a href ="http://www.cidoc-crm.org/docs/cidoc_crm_version_6.0.pdf">CIDOC-CRM E92-Spacetime Volume</a>). <a href="https://github.com/geojson/geojson-ld/issues?q=is%3Aissue+is%3Aclosed">Another</a> seeks to add a "when" component to the "where" (geometry) of GeoJSON and GeoJSON-LD.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a></p>
          <p class="relatedRequirements"><a href="#DateTimeDuration"></a>, <a href="#4DModelSpaceTime"></a>, <a href="#TemporalMultiScale"></a>, <a href="#TemporalReferenceSystem"></a>, <a href="#TemporalVagueness"></a>, <a href="#ValidTime"></a></p>
        </section>
        <section id="CreationOfVirtualObservationsfromAnalysisPhaseOfWeatherPredictionModel">
          <h3>Creation of “virtual observations” from “analysis” phase of weather prediction model</h3>
          <p class="contributor">Jeremy Tandy, <a href="http://www.metoffice.gov.uk/">Met Office</a></p>
          <label class="expand" for="uc46"></label>
          <input id="uc46" type="checkbox">
          <div>
            <p>National Meteorological Services (NMS), such as  <a href="http://www.metoffice.gov.uk/">Met Office</a>, maintain a network of weather observation sites within their region of responsibility in order, amongst other things, to provide input to their numerical weather prediction models. The cost of maintaining these weather observation sites means that their number is limited.</p>
            <p>Within the UK, and likely in other places too, there is a high demand for weather observations for specific locations. To meet this demand, the Met Office provides data for many more locations than the number of weather observation sites they maintain. In order to do this, “virtual observations” for these locations are derived from the “analysis” of the numerical weather prediction model. (“Analysis” is the term used to describe the initial state of the numerically modelled atmosphere from which the forecast is calculated; it incorporates real observations and provides a dynamically balanced representation of the atmosphere at a snapshot in time.)</p>
            <p>The metadata needed to provide context to a “virtual observation" is identical to that for normal observations; albeit that the procedure used to create the observation involves a computational simulation rather than a physical sensor and stimulus. Clearly, it is important to provide information about the procedure used to create the observation so that “real” observations can be distinguished from “virtual” observations.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a></p>
          <p class="relatedRequirements"><a href="#Provenance"></a>, <a href="#VirtualObservations"></a>, <a href="#SensingProcedure"></a></p>
        </section>
        <section id="IncorporatingGeospatialDataIntoInteractive3DGraphicsOnTheWeb">
          <h3>Incorporating geospatial data (e.g. geo-referenced geometry) into interactive 3D graphics on the web </h3>
          <p class="contributor">Stefan Lemme, DFKI/Saarland University</p>
          <label class="expand" for="uc47"></label>
          <input id="uc47" type="checkbox">
          <div>
            <p>This use case relates to <a href="#ConsumingGeographicalDataInAWebApplication"></a> and maintains the bridge 3D-web applications (without targeting the actual rendering process, which is out-of-scope).</p>
            <p>Visualizing geospatial data, such as geo-referenced 3D geometry of building, is a crucial capability even for web applications. This use case targets web developers that are using 3D graphics in their (existing) web applications. To ease the pick up of 3D graphics for web developers, since they are usually non-graphics experts, the  <a href="https://www.w3.org/community/declarative3d/">Declarative 3D for the Web Architecture Community Group</a> of W3C did previous work to determine the requirements, options, and use cases for an integration of interactive 3D graphics capabilities into the W3C technology stack. Thereby, they propose a declarative approach to describe the 3D scene content as an extension of HTML5 rather than interfacing low-level APIs for rendering. Several implementations, such as X3D, X3DOM, and <a href="http://xml3d.org/">XML3D</a>, address this approach. However, web developers are usually non-geospatial experts. Thus, to achieve a similar low-entrance barrier for them to incorporate geospatial data into interactive 3D graphics on the web, any (web)service providing geospatial data (including geometry) might consider a compatible content delivery format and API. Firstly, this implies none to only very little processing overhead on the client. In particular, when having mobile web applications in mind an efficient content delivery (bandwidth-wise as well as client-side-processing-wise) is becoming important. Secondly, web developers utilize established libraries, such as jQuery, to interface remote (RESTful) APIs. To ease interfacing geospatial services, web developers tend to reuse their tools. Finally, existing best practices of the web should be taken into account and applied to the access of geospatial data according, such as paging of result sets, caching of resources at several stages (server, browser), etc.
            <ol>
              <li><a href="http://earthlook.org/demo/elevation/elevation-client-bgs.html">Sample 3D client based on WCS/WCPS</a></li>
              <li><a href="http://130.206.80.175/poi-client/single-tile-brussels.html">Examples using XML3D and OSM data</a></li>
              <li><a href="http://130.206.80.175/poi-client/buildings-tum-static.html">Examples using XML3D and OSM data</a></li>
            </ol></p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <!-- TO DO: link related use cases -->
        <!-- Template for use cases
        <section id="">
          <h3></h3>
          <p class="contributor"></p>
          <label class="expand" for="ucX"></label>
          <input id="ucX" type="checkbox">
          <div>
            <p></p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        -->
      </section>
      </br>
      <section id="Requirements">
      <h2>Requirements</h2>
      <p>This chapter lists the requirements for the deliverables of the Working Group, in alphabetical order.</p>
      <section id="BoundingBoxCentroid">
        <h3>Bounding box and centroid</h3>
        <p>There should be a common standard for publishing and requesting the bounding box and centroid of a spatial thing.</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#PublishingGeographicalData"></a>, <a href="#GeospatialExtensionsToDomainIndependentMetadataSchemas"></a></p>
      </section>
      <section id="CitizensAsSensors">
        <h3>Citizens as sensors</h3>
        <p>It should be possible to describe the role of people or communities acting as sensors perceiving the environment.</p>
        <p class="relatedDeliverables"> <a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#DrivingToWorkInTheSnow"></a>, <a href="#SatelliteDataProcessing"></a>, <a href="#MarineObservationsDataProviders"></a>, <a href="#CrowdSourcedEarthquakeObservationInformation"></a>, ...</p>
      </section>  
		<section id="Compatibility">
        <h3>Compatibility with existing practices</h3>
        <p>Standards for spatial data on the web should be compatible with existing methods of making spatial data available (like WFS, WMS, CSW, WCS).</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#PublishingGeographicalData"></a>, <a href="#UsingSpatialDataFromTheWebInGISSystemsDuringEmergencyResponseOperations"></a>, <a href="#INSPIREComplianceUsingWebStandards"></a></p>
      </section>    
		<section id="Compressable">
        <h3>Compressable</h3>
        <p>Spatial data on the web should be compressable (for optimization of data transfer).</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#DutchBaseRegistry"></a></p>
      </section>  
      <section id="Crawlability">
        <h3>Crawlability</h3>
        <p>Spatial data on the web should be crawlable, allowing data to be found and indexed by external agents.</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#MeteorologicalDataRescue"></a>, <a href="#HarvestingLocalSearchContent"></a>, <a href="#ConsumingGeographicalDataInAWebApplication"></a></p>
      </section>
      <section id="CRSDefinition">
        <h3>CRS definition</h3>
        <p>The URI of the Coordinate Reference System (CRS) shall be specified when geographic coordinates are present in the data. To be considered as sub-requirement of <a href="#SpatialMetadata"></a></p>
        <p class="relatedDeliverables"><a href="#SSN"></a><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#DiachronicBurntScarMapping"></a>, <a href="#MeteorologicalDataRescue"></a>, <a href="#RealtimeWildfireMonitoring"></a>, <a href="#SatelliteDataProcessing"></a>, <a href="#SpatialSampling"></a>, ...</p>
      </section>
      <section id="DateTimeDuration">
        <h3>Date, time and duration</h3>
        <p>It should be possible to represent dates, time and duration.</p>
        <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a></p>
        <p class="relatedUseCases"><a href="#DrivingToWorkInTheSnow"></a>, <a href="#EventlikeGeographicFeatures"></a>, <a href="#HarvestingLocalSearchContent"></a>, <a href="#IntelligentTransportationSystem"></a>, <a href="#LandsatDataServices"></a>, <a href="#MeteorologicalDataRescue"></a>, <a href="#ObservationsOnGeologicalSamples"></a>, <a href="#PublicationOfAirQualityDataAggregations"></a>, <a href="#SelectHierarchicalGeographicalRegionsForUseInDataAnalysisOrVisualisation"></a></p>
      </section>
      <section id="DifferentTimeModels">
        <h3>Different time models</h3>
        <p>It should be possible to represent data using different time models, such as geological time and non-Gregorian calendars.</p>
        <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a></p>
        <p class="relatedUseCases"><a href="#MetadataAndSearchGranularity"></a>, <a href="#MeteorologicalDataRescue"></a>, <a href="#ObservationsOnGeologicalSamples"></a>, <a href="#UseOfAPlaceNameOntologyForGeo-parsingTextAndGeo-enablingSearches"></a></p>
      </section>
      <section id="Discoverability">
        <h3>Discoverability</h3>
        <p>It should be easy to find spatial data on the web, e.g. by means of metadata aimed at discovery. When spatial data are published on the web, both humans and machines should be able to discover those data.</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#CoverageInLinkedData"></a></p>
        <p class="relatedUseCases"><a href="#BushfireResponseCoordinationCentre"></a>, <a href="#ConsumingGeographicalDataInAWebApplication"></a>, <a href="#CropYieldEstimationUsingMultipleSatellites"></a>, <a href="#DrivingToWorkInTheSnow"></a>, <a href="#EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities"></a>, <a href="#HarvestingLocalSearchContent"></a>, <a href="#ImagesEGATimeSeriesOfAWaterCourse"></a>, <a href="#ImprovingDiscoveryOfSpatialDataOnTheWeb"></a>, <a href="#IntegrationOfGovernmentalAndUtilityDataToEnableSmartGrids"></a>, <a href="#IntelligentTransportationSystem"></a>, <a href="#LandsatDataServices"></a>, <a href="#MarineObservationsEMII"></a>, <a href="#MeteorologicalDataRescue"></a>, <a href="#MetadataAndSearchGranularity"></a>, <a href="#SoilDataApplications"></a>, <a href="#UsingSpatialDataFromTheWebInGISSystemsDuringEmergencyResponseOperations"></a></p>
      </section>
      <section id="DynamicSensorData">
        <h3>Dynamic sensor data</h3>
        <p>It should be possible to represent near real-time streaming sensor measurements.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#RealtimeWildfireMonitoring"></a>, <a href="#DrivingToWorkInTheSnow"></a>, <a href="#DroughtsInGeologicalComplexEnvironmentsWhereGroundwaterIsImportant"></a></p>
      </section>
      <section id="EncodingForVectorGeometry">
        <h3>Encoding for vector geometry</h3>
        <p>There should be a standard for encoding vector geometry (an expression of spatial data that uses coordinates) when such data are published on the web.</p>
        <p class="relatedDeliverables"></a><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#PublishingGeographicalData"></a>, <a href="#ConsumingGeographicalDataInAWebApplication"></a>, <a href="#CombiningSpatialRDFDataForIntegratedQueryingInATriplestore"></a>, <a href="#IntelligentTransportationSystem"></a>, <a href="#INSPIREComplianceUsingWebStandards"></a><a href="#PublishingCulturalHeritageData"></a></p>
      </section>
      <section id="ExSituSampling">
        <h3>Ex-situ sampling</h3>
        <p>It should be possible to represent ex-situ (remote) sampling or sensing.</p>
        <p class="relatedDeliverables"></a><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#ObservationsOnGeologicalSamples"></a></p>
      </section>
      <section id="GeoreferencedSensorData">
        <h3>Georeferenced sensor data</h3>
        <p>It should possible to georeference observations.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#HabitatZoneVerification"></a>, <a href="#DrivingToWorkInTheSnow"></a>, <a href="#ImagesEGATimeSeriesOfAWaterCourse"></a>, <a href="#ObservationsOnGeologicalSamples"></a>, <a href="#SpatialSampling"></a>, <a href="#SatelliteDataProcessing"></a>, <a href="#MarineObservationsDataProviders"></a>, ...</p>
      </section>
      <section id="IndependenceOnReferenceSystems">
        <h3>Independence on reference systems</h3>
        <p>Standards for spatial data on the web should be independent on the reference systems that are used for data.</p>
        <p><i>Note: This requirement reflects that spatial data incorporate geographical data, but can also be data that are not directly related to earth or its scale.</i></p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#LocatingAThing"></a>, <a href="#ConsumingGeographicalDataInAWebApplication"></a>, <a href="#EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities"></a>, <a href="#SatelliteDataProcessing"></a>, <a href="#TCGAMicroscopyImaging"></a></p>
      </section>
      <section id="LightweightAPI">
        <h3>Lightweight API</h3>
        <p>A lightweight API is needed for implementation on IoT devices.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#DrivingToWorkInTheSnow"></a></p>
      </section>
      <section id="Linkability">
        <h3>Linkability</h3>
        <p>Spatial data on the Web should be linkable (by explicit relationships between different facts in different data sets), to other spatial data and to or from other types of data.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a>, <a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#BushfireResponseCoordinationCentre"></a>, <a href="#DiachronicBurntScarMapping"></a>, <a href="#DroughtsInGeologicalComplexEnvironmentsWhereGroundwaterIsImportant"></a>, <a href="#ObservationsOnGeologicalSamples"></a>, <a href="#OptimizingEnergyConsumptionProductionSalesAndPurchasesInSmartGrids"></a>, <a href="#RealtimeWildfireMonitoring"></a>, <a href="#SpatialSampling"></a>, <a href="#EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities"></a>, <a href="#PublishingGeospatialReferenceData"></a>, <a href="#DutchBaseRegistry"></a>, <a href="#MeteorologicalDataRescue"></a></p>
      </section>
      <section id="MachineToMachine">
        <h3>Machine to machine</h3>
        <p>Standards for spatial data on the web should work well in machine to machine environments.</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#LocatingAThing"></a></p>
      </section>
      <section id="MobileSensors">
        <h3>Mobile sensors</h3>
        <p>It should be possible to represent sensors that change their location, as well as the current location of the sensor at the observation time.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a> ...</p>
        <p class="relatedUseCases"></a><a href="#DrivingToWorkInTheSnow"></a>, <a href="#IntelligentTransportationSystem"></a>, <a href="#MarineObservationsEMII"></a>, <a href="#PublicationOfAirQualityDataAggregations"></a>, <a href="#SpatialSampling"></a>, <a href="#SatelliteDataProcessing"></a>, ...</p>
      </section>
		<section id="4DModelSpaceTime">
        <h3>4D model of space-time</h3>
        <p>It should be possible to represent spatial extent directly bound to time, e.g. journey trajectories.</p>
        <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a></p>
        <p class="relatedUseCases"><a href="#EventlikeGeographicFeatures"></a></p>
      </section>      
      <section id="ModelReuse">
        <h3>Model reuse</h3>
        <p>Spatial data modelling issues solved in existing observation models shall be considered for adoption, e.g. O&M.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#MarineObservationsEMII"></a>, <a href="#ObservationsOnGeologicalSamples"></a>, <a href="#PublicationOfAirQualityDataAggregations"></a>, <a href="#SoilDataApplications"></a>, <a href="#SpatialSampling"></a>, ...</p>
      </section>
      <section id="MovingFeatures">
        <h3>Moving features</h3>
        <p>It should be possible to refer to features that change their location.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#DrivingToWorkInTheSnow"></a>, <a href="#IntelligentTransportationSystem"></a>, ...</p>
      </section>
      <section id="MultilingualSupport">
        <h3>Multilingual support</h3>
        <p>It should be possible to add metadata in different languages.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#MeteorologicalDataRescue"></a>, <a href="#CrowdSourcedEarthquakeObservationInformation"></a>, ...</p>
      </section>
      <section id="NominalObservations">
        <h3>Nominal observations</h3>
        <p>it should be possible to represent qualitative and nominal observations.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#DrivingToWorkInTheSnow"></a>, <a href="#IntelligentTransportationSystem"></a>, <a href="#DroughtsInGeologicalComplexEnvironmentsWhereGroundwaterIsImportant"></a>, <a href="#SatelliteDataProcessing"></a>, <a href="#MarineObservationsDataProviders"></a>, <a href="#CrowdSourcedEarthquakeObservationInformation"></a>, ...</p>
      </section>
		<section id="NominalTemporalReferences">
        <h3>Nominal temporal references</h3>
        <p>It should be possible to refer to time intervals by nominal temporal references (e.g January, a named event in a calendar, a geological period, a dynastic period).</p>
        <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a></p>
        <p class="relatedUseCases"><a href="#DrivingToWorkInTheSnow"></a>, <a href="#EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities"></a>, <a href="#MetadataAndSearchGranularity"></a>, <a href="#MeteorologicalDataRescue"></a>, <a href="#PublishingCulturalHeritageData"></a></p>
      </section>
      <section id="ObservationAggregations">
        <h3>Observation aggregations</h3>
        <p>It should be possible to represent aggregations of observations.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"> <a href="#MarineObservationsEMII"></a>, <a href="#PublicationOfAirQualityDataAggregations"></a>, <a href="#SoilDataApplications"></a>, ...</p>
      </section>
      <section id="PositioningSystem">
        <h3>Positioning system</h3>
        <p>It should be possible to define the positioning system used to determine the spatial location in the data. To be considered as sub-requirement of <a href="#SpatialMetadata"></a></p>
        <p class="relatedDeliverables"><a href="#SSN"></a>, ...</p>
        <p class="relatedUseCases"><a href="#CrowdSourcedEarthquakeObservationInformation"></a>, <a href="#SatelliteDataProcessing"></a>, <a href="#SpatialSampling"></a>, ...</p>
      </section>
      <section id="Provenance">
        <h3>Provenance</h3>
        <p>It should be possible to add provenance metadata.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a>, <a href="#CoverageInLinkedData"></a></p> 
        <p class="relatedUseCases"><a href="#CreationOfVirtualObservationsfromAnalysisPhaseOfWeatherPredictionModel"></a>, <a href="#DiachronicBurntScarMapping"></a>, <a href="#DroughtsInGeologicalComplexEnvironmentsWhereGroundwaterIsImportant"></a>, <a href="#HabitatZoneVerification"></a>, <a href="#MeteorologicalDataRescue"></a>, <a href="#ObservationsOnGeologicalSamples"></a>, <a href="#RealtimeWildfireMonitoring"></a>, <a href="#SatelliteDataProcessing"></a></p>
      </section>
      <section id="QualityMetadata">
        <h3>Quality metadata</h3>
        <p>It should be possible to describe the data quality.</p>
        <p class="relatedDeliverables"><a href="#CoverageInLinkedData"></a></p>
        <p class="relatedUseCases"><a href="#MeteorologicalDataRescue"></a>, <a href="#DroughtsInGeologicalComplexEnvironmentsWhereGroundwaterIsImportant"></a>, <a href="#MarineObservationsEMII"></a>, <a href="#SoilDataApplications"></a></p>
      </section>
      <section id="ReferenceExternalVocabularies">
        <h3>Reference external vocabularies</h3>
        <p>It should be possible to refer to externally-managed controlled vocabularies.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#PublicationOfAirQualityDataAggregations"></a>, <a href="#ObservationsOnGeologicalSamples"></a>, <a href="#SoilDataApplications"></a>, <a href="#MeteorologicalDataRescue"></a></p>
      </section>
      <section id="SamplingTopology">
        <h3>Sampling topology</h3>
        <p>It should be possible to represent sensing topological relationships, e.g. project, sensor, stream, observation.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#SpatialSampling"></a>, <a href="#MarineObservationsEMII"></a></p>
      </section>
      <section id="SensorDataTimeSeries">
        <h3>Sensor data time series</h3>
        <p>It must be possible to represent time series of sensor data.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#PublicationOfRawSubsurfaceMonitoringData"></a>, <a href="#ImagesEGATimeSeriesOfAWaterCourse"></a></p>
      </section>
      <section id="SensorMetadata">
        <h3>Sensor metadata</h3>
        <p>It should be possible to include metadata about the sensors producing the observations.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#MeteorologicalDataRescue"></a>, <a href="#RealtimeWildfireMonitoring"></a>, <a href="#DiachronicBurntScarMapping"></a>, <a href="#IntegrationOfGovernmentalAndUtilityDataToEnableSmartGrids"></a>, <a href="#DrivingToWorkInTheSnow"></a>, <a href="#BushfireResponseCoordinationCentre"></a>, <a href="#ObservationsOnGeologicalSamples"></a>, <a href="#SpatialSampling"></a>, <a href="#SatelliteDataProcessing"></a>, <a href="#MarineObservationsEMII"></a>, ...</p>
      </section>
      <section id="SensingProcedure">
        <h3>Sensing procedure</h3>
        <p>It should be possible to attach the procedural description of a sensing method.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#SatelliteDataProcessing"></a>, <a href="#CreationOfVirtualObservationsfromAnalysisPhaseOfWeatherPredictionModel"></a>, <a href="#MeteorologicalDataRescue"></a></p>
      </section>
		<section id="SpaceTimeMultiScale">
        <h3>Space-time multi-scale</h3>
        <p>It should be possible to represent and integrate data over spatial and temporal scales.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a>, <a href="#TimeOntologyInOWL"></a>, ...</p>
        <p class="relatedUseCases"></a><a href="#ImagesEGATimeSeriesOfAWaterCourse"></a>, <a href="#IntelligentTransportationSystem"></a>, <a href="#MeteorologicalDataRescue"></a>, <a href="#SoilDataApplications"></a>, <a href="#SpatialSampling"></a>, ...</p>
      </section>      
      <section id="SpatialMetadata">
        <h3>Spatial metadata</h3>
        <p>There should be standards that allow data sources (data sets or data services) to describe their spatial characteristics, like:
        <ul>
        <li>number of dimensions (1D, 2D, 3D)</li>
        <li>data type (raster or vector)</li>
        <li>Cooordinate Reference System(s)</li>
        <li>spatial extent</li>
        <li>spatial resolution</li>
        </ul>
        </p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a> ...</p>
        <p class="relatedUseCases"></a><a href="#MeteorologicalDataRescue"></a>, <a href="#HarvestingLocalSearchContent"></a>, <a href="#PublishingGeographicalData"></a>, <a href="#ConsumingGeographicalDataInAWebApplication"></a>, <a href="#UsingSpatialDataFromTheWebInGISSystemsDuringEmergencyResponseOperations"></a>, <a href="#CombiningSpatialRDFDataForIntegratedQueryingInATriplestore"></a>, <a href="#PublicationOfRawSubsurfaceMonitoringData"></a>, <a href="#IntelligentTransportationSystem"></a>, <a href=""></a>, <a href="#ImagesEGATimeSeriesOfAWaterCourse"></a>, <a href="#SoilDataApplications"></a>, <a href="#LandsatDataServices"></a>, <a href="#MetadataAndSearchGranularity"></a>, <a href="#GeospatialExtensionsToDomainIndependentMetadataSchemas"></a>, <a href="#ImprovingDiscoveryOfSpatialDataOnTheWeb"></a>, <a href="#INSPIREComplianceUsingWebStandards"></a></p>
      </section>
      <section id="SpatialMeronymy">
        <h3>Spatial meronymy</h3>
        <p>There should be a standard for describing spatial hierarchy. The <a href="http://dublincore.org/documents/dcmi-terms/">Dublin Core metadata vocabulary</a> contains the terms <a href="http://dublincore.org/documents/dcmi-terms/#terms-hasPart">hasPart</a> and <a href="http://dublincore.org/documents/dcmi-terms/#terms-isPartOf">isPartOf</a>. Can those terms be recommended for specifying spatial hierarchy? Or is something else needed?</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#HabitatZoneVerification"></a>, <a href="#LocatingAThing"></a>, <a href="#PublishingGeographicalData"></a>, <a href="#EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities"></a>, <a href="#SelectHierarchicalGeographicalRegionsForUseInDataAnalysisOrVisualisation"></a></p>
      </section>
      <section id="SpatialOperators">
        <h3>Spatial operators</h3>
        <p>There should be common standards for spatial operators. Spatial things can have spatial relations: topological relations, directional or distance relations. Operators based on these relations (e.g. 'Contains'. 'Intersects', 'Nearest') should be standardised.</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#ConsumingGeographicalDataInAWebApplication"></a>, <a href="#EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities"></a>, <a href="#SelectHierarchicalGeographicalRegionsForUseInDataAnalysisOrVisualisation"></a>, <a href="#MetadataAndSearchGranularity"></a>, <a href="#ImprovingDiscoveryOfSpatialDataOnTheWeb"></a></p>
      </section>
      <section id="SpatialVagueness">
        <h3>Spatial vagueness</h3>
        <p>It should be possible to describe locations in a vague, imprecise manner.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a>, <a href="#Coverage"></a></p>
        <p class="relatedUseCases"><a href="#BushfireResponseCoordinationCentre"></a>, <a href="#MeteorologicalDataRescue"></a>, <a href="#SpatialSampling"></a>, <a href="#CrowdSourcedEarthquakeObservationInformation"></a>, <a href="#PublishingCulturalHeritageData"></a>, </p>
      </section>
      <section id="Streamable">
        <h3>Streamable data</h3>
        <p>Data should be streamable, a consumer should be able to do something meaningful before the end of the data message is received. This could be considered a general requirement for data on the web, but it is recorded here because spatial data often consist of large chunks of data.</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#ConsumingGeographicalDataInAWebApplication"></a></p>
      </section>
      <section id="3DSupport">
        <h3>Support for 3D</h3>
        <p>All standards for spatial data on the Web should be applicable to three-dimensional data.</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#PublishingGeographicalData"></a>, <a href="#PublicationOfRawSubsurfaceMonitoringData"></a>, <a href="#UseOfAPlaceNameOntologyForGeo-parsingTextAndGeo-enablingSearches"></a>, <a href="#ImagesEGATimeSeriesOfAWaterCourse"></a>, <a href="#DroughtsInGeologicalComplexEnvironmentsWhereGroundwaterIsImportant"></a>, <a href="#BuildingInformationManagementAndDataSharing"></a>, <a href="#CrowdSourcedEarthquakeObservationInformation"></a>, <a href="#TCGAMicroscopyImaging"></a>, <a href="#MarineObservationsEMII"></a>, <a href="#MarineObservationsDataProviders"></a>, <a href="#CropYieldEstimationUsingMultipleSatellites"></a></p>
      </section>
      <section id="TemporalMultiScale">
        <h3>Temporal multi-scale</h3>
        <p>It should be possible to represent and integrate data over temporal scales (to be considered sub-requirement of <a href="#SpaceTimeMultiScale"></a>)</p>
        <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a></p>
        <p class="relatedUseCases"><a href="#EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities"></a>, <a href="#EventlikeGeographicFeatures"></a>, <a href="#MetadataAndSearchGranularity"></a>, <a href="#PublishingCulturalHeritageData"></a></p>
      </section>
      <section id="TemporalReferenceSystem">
        <h3>Temporal reference system</h3>
        <p>The temporal reference system should be specified.</p>
        <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a></p>
        <p class="relatedUseCases"><a href="#EventlikeGeographicFeatures"></a>, <a href="#IntelligentTransportationSystem"></a>, <a href="#MetadataAndSearchGranularity"></a>, <a href="#MeteorologicalDataRescue"></a>, <a href="#UseOfAPlaceNameOntologyForGeo-parsingTextAndGeo-enablingSearches"></a></p>
      </section>
      <section id="TemporalVagueness">
        <h3>Temporal vagueness</h3>
        <p>It should be possible to describe time points and intervals in a vague, imprecise manner.</p>
        <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a></p>
        <p class="relatedUseCases"><a href="#EnablingPublicationDiscoveryAndAnalysisOfSpatiotemporalDataInTheHumanities"></a>, <a href="#EventlikeGeographicFeatures"></a>, <a href="#PublishingCulturalHeritageData"></a></p>
      </section>
      <section id="TilingSupport">
        <h3>Support for tiling</h3>
        <p>Standards for spatial data on the web should support tiling (for raster and vector data). Tiling of spatial data can drastically improve the speed of data retrieval and allows having simple caches of data around the web.</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#ConsumingGeographicalDataInAWebApplication"></a></p>
        </p>
      </section>
      <section id="TimeSeries">
        <h3>Time series</h3>
        <p>It should be possible to represent time series.</p>
        <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a></p>
        <p class="relatedUseCases"><a href="#LandsatDataServices"></a>, <a href="#PublicationOfRawSubsurfaceMonitoringData"></a></p>
        </p>
      </section>
      <section id="UncertaintyInObservations">
        <h3>Uncertainty in observations</h3>
        <p>It must be possible to represent uncertainty in observations.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#MarineObservationsDataProviders"></a>, <a href="#MeteorologicalDataRescue"></a>, <a href="#SpatialSampling"></a></p>
      </section>
		<section id="ValidTime">
        <h3>Valid time</h3>
        <p>It should be possible to represent the time of validity that applies to a thing, state or fact.</p>
        <p class="relatedDeliverables"><a href="#TimeOntologyInOWL"></a></p>
        <p class="relatedUseCases"><a href="#EventlikeGeographicFeatures"></a>, <a href="#SelectHierarchicalGeographicalRegionsForUseInDataAnalysisOrVisualisation"></a>, <a href="#UseOfAPlaceNameOntologyForGeo-parsingTextAndGeo-enablingSearches"></a></p>
      </section>
      <section id="VirtualObservations">
        <h3>Virtual observations</h3>
        <p>It must be possible to represent synthetic observations made by computational procedures or inference.</p>
        <p class="relatedDeliverables"><a href="#SSN"></a></p>
        <p class="relatedUseCases"><a href="#DroughtsInGeologicalComplexEnvironmentsWhereGroundwaterIsImportant"></a>, <a href="#SoilDataApplications"></a>, <a href="#SatelliteDataProcessing"></a>, <a href="#CropYieldEstimationUsingMultipleSatellites"></a>, <a href="#CreationOfVirtualObservationsfromAnalysisPhaseOfWeatherPredictionModel"></a></p>
      </section>
      <!-- Template for requirements:
       <section id="">
        <h3></h3>
        <p></p>
        <p class="relatedDeliverables"><a href=""></a>, <a href=""></a></p>
        <p class="relatedUseCases"><a href=""></a>, <a href=""></a></p>
      </section>
      -->
    </section>
  </body>

