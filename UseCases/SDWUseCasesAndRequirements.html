<!DOCTYPE html>
<html lang="en" dir="ltr" typeof="bibo:Document " prefix="bibo: http://purl.org/ontology/bibo/ w3p: http://www.w3.org/2001/02pd/rec54#">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta lang="" property="dc:language" content="en">
  <meta content="width=device-width,initial-scale=1" name="viewport">
  <title>Spatial Data on the Web Use Cases &amp; Requirements</title>
  <script src='http://www.w3.org/Tools/respec/respec-w3c-common' async class='remove'></script>
  <style type="text/css">
  .contributor:before {
    content: "Contributed by: ";
    font-weight: bold;
  }
  .relatedDeliverables:before {
    content: "Related deliverables: ";
    font-weight: bold;
  }
  .relatedRequirements:before {
    content: "Related requirements: ";
    font-weight: bold;
  }
  .relatedUseCases:before {
    content: "Related use cases: ";
    font-weight: bold;
  }
  .expand{
    display:block;
  }
  .expand:before {
    font-weight: bold;
    content: "\25BA Full use case description (click to expand or collapse):";
  }
  .expand + input{
    display:none;
  }
  .expand + input + *{
    display:none;
  }
  .expand + input:checked + *{
    display:block;
  }
  </style> 
  <script class='remove'>
    var respecConfig = {
      specStatus: "ED",
      shortName: "sdw-ucr",
      //publishDate:  "2015-02-12",
      //previousPublishDate: "2014-03-27",
      //previousMaturity: "FPWD",
      //previousURI: "http://www.w3.org/TR/2014/WD-tabular-data-model-20140327/",
      edDraftURI: "http://w3c.github.io/sdw/UseCases/SDWUseCasesAndRequirements.html",
      // lcEnd: "3000-01-01",
      // crEnd: "3000-01-01",
      editors: [
      {
        name: "Frans Knibbe",
        company: "Geodan",
        companyURL: "http://www.geodan.nl/"
      },
      {
        name: "Alejandro Llaves",
        company: "Universidad Politécnica de Madrid",
        companyURL: "http://www.upm.es/"
      }],
      wg: "Spatial Data on the Web Working Group",
      wgURI: "http://www.w3.org/2015/spatial/",
      wgPublicList: "public-sdw-wg",
      wgPatentURI: "http://www.w3.org/2004/01/pp-impl/68239/status",
      inlineCSS: true,
      noIDLIn: true,
      noLegacyStyle: false,
      logos: [
      {
        src: "http://www.w3.org/Icons/w3c_home",
        alt: "W3C",
        height: "48",
        width: "72",
        url: "http://www.w3.org/"
      },
      {
        src: "http://www.w3.org/2015/01/ogc_logo.jpg",
        alt: "OGC",
        height: "48",
        width: "115",
        url: "http://www.opengeospatial.org/"
      }
      ],
      noRecTrack: true,
      overrideCopyright: "<p class='copyright'><a href='http://www.w3.org/Consortium/Legal/ipr-notice#Copyright'>Copyright</a> © 2015 <a href='http://www.opengeospatial.org/'>OGC</a> &amp; <a href='http://www.w3.org/'> <abbr title='World Wide Web Consortium'>W3C</abbr> </a><sup>®</sup> (<a href='http://www.csail.mit.edu/'><abbr title='Massachusetts Institute of Technology'>MIT</abbr></a>, <a href='http://www.ercim.eu/'><abbr title='European Research Consortium for Informatics and Mathematics'>ERCIM</abbr></a>, <a href='http://www.keio.ac.jp/'>Keio</a>, <a href='http://ev.buaa.edu.cn/'>Beihang</a>), <abbr title='World Wide Web Consortium'>W3C</abbr> <a href='http://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer'>liability</a>, <a href='http://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks'>trademark</a> and <a href='http://www.w3.org/Consortium/Legal/copyright-documents'>document use</a> rules apply.</p>"
    };
  </script>
  <body>
    <section id='abstract'>
      <p>
        This document is the first deliverable of the <a href="http://www.w3.org/2015/spatial/">Spatial Data on the Web Working Group</a>. It describes uses cases and requirements for further work that are derived from the use cases.
      </p>
    </section>
    <section id='sotd'>
    </section>
    <section>
      <h2>Introduction</h2>
      <p>
        The mission of the <a href="http://www.w3.org/2015/spatial/">Spatial Data on the Web Working Group</a>, as described in the <a href="http://www.w3.org/2015/spatial/charter">charter</a>, is to clarify and to formalize standards on spatial data on the web. In particular:
        <ol>
        <li>to determine how spatial information can best be integrated with other data on the Web;</li>
        <li>to determine how machines and people can discover that different facts in different datasets relate to the same place, especially when 'place' is expressed in different ways and at different levels of granularity;</li>
        <li>to identify and assess existing methods and tools and then create a set of best practices for their use;</li>
        <li>where desirable, to complete the standardization of informal technologies already in widespread use.</li>
        </ol>
        This document describes the results of the first steps of working towards these goals. Members of the working group and other stakeholders have come up with a number of <a href="#UseCases">use cases</a> that describe how spatial data on the web could work. From these use cases, a number of <a href="#Requirements">requirements</a> for further work are derived. In this document, use cases, requirements and their relationships are described. Requirements and use cases are also related to the <a href="#Deliverables">deliverables</a> of the working group.      
      </p>
      <p>
        The requirements described in this document will be the basis for development of the other four deliverables of the Working Group.
      </p>
    </section>
    <section id="Deliverables">
      <h2>Deliverables</h2>
      <p>
      The deliverables of this Working Group are described in the <a href="http://www.w3.org/2015/spatial/charter">Working Group Charter</a>. For convenience, and to have URIs, those deliverables are replicated in this chapter. The charter remains the authorative source of the definition of deliverables.
      </p>
      <section id="UseCasesAndRequirements">
        <h3>Use Cases and Requirements</h3>
        <p>A document setting out the range of problems that the working groups are trying to solve (this document).</p>
      </section>
      <section id="BestPractices">
        <h3>Spatial Data on the Web Best Practices</h3>
        <p>This will include:
        <ul>
        <li>an agreed spatial ontology conformant to the ISO 19107 abstract model and based on existing available ontologies such as GeoSPARQL, NeoGeo and the ISA Core Location vocabulary;</li>
        <li>advice on use of URIs as identifiers in GI systems;</li>
        <li>advice on providing different levels of metadata for different usage scenarios (from broad sweep metadata to metadata about individual coordinates in a polygon);</li>
        <li>develop advice on, or possibly define, RESTful APIs to return data in a variety of formats including those defined elsewhere, such as GeoJSON, GeoJSON-LD and TopoJSON.</li>
        </ul>
        </p>
      </section>
      <section id="TimeOntologyInOWL">
        <h3>Time Ontology in OWL</h3>
        <p>The WG will work with the authors of the existing Time Ontology in OWL to complete the development of this widely used ontology through to Recommendation status. Further requirements already identified in the geospatial community will be taken into account.</p>
      </section>
      <section id="SemanticSensorNetworkVocabulary">
        <h3>Semantic Sensor Network Vocabulary</h3>
        <p>The WG will work with the members of the former Semantic Sensor Network Incubator Group to develop its ontology into a formal Recommendation, noting the work to split the ontology into smaller sections to offer simplified access.</p>
      </section>
      <section id="CoverageInLinkedData">
        <h3>Coverage in Linked Data</h3>
        <p>The WG will develop a formal Recommendation for expressing discrete coverage data conformant to the ISO 19123 abstract model. Existing standard and de facto ontologies will be examined for applicability; these will include the RDF Data Cube. The Recommendation will include provision for describing the subset of coverages that are simple timeseries datasets - where a time-varying property is measured at a fixed location. OGC's WaterML 2 Part 1 - Timeseries will be used as an initial basis.</p>
        <p>Given that coverage data can often be extremely large in size, publication of the individual data points as Linked Data may not always be appropriate. The Recommendation will include provision for describing an entire coverage dataset and subsets thereof published in more compact formats using Linked Data. For example where a third party wishes to annotate a subset of a large coverage dataset or a data provider wishes to publish a large coverage dataset in smaller subsets to support convenient reuse.</p>
      </section>
    </section>
    <section id="Scoping">
      <h2>Scoping</h2>
      <p>The Working Group has derived requirements from the collected use cases. Care was taken to only derive requirements that are considered to in scope for the further work of the Working Group. To aid in this process, the following scoping questions were applied:
      <ol>
      <li>Is the use case specifically about Spatial data on the Web?</li>
      <li>Is the use case including data published, reused, and accessible via Web technologies?</li>
      <li>Has a use case a description that can lead to a testable requirement?</li>
      </ol>
      </p>
    </section>
    <section id="UseCases">
      <h2>Use Cases</h2>
        <p>Use cases that describe current problems or future opportunities for spatial data on the web have been gathered as a first activity of the Working Group. They were mainly contributed by members of Working Group, but there were also contributions from other interested parties. In this chapter the use cases are listed and identified. Each use case is related to one or more Working Group <a href="#Deliverables">deliverables</a>. The use cases were analyzed by the Working Group, which led to a set of <a href="#Requirements">requirements</a> for future deliverables. For each use case related requirements are also listed.</p>
        <!-- Template for use cases
        <section id="">
          <h3></h3>
          <p class="contributor"></p>
          <label class="expand" for="ucX"></label>
          <input id="ucX" type="checkbox">
          <div>
          <p></p>
          </div>
          <p class="relatedDeliverables"></p>
          <p class="relatedRequirements"></p>
        </section>
        -->
        <section id="MeteorologicalDataRescue">
          <h3>Meteorological Data Rescue</h3>
          <p class="contributor">Chris Little, based on scenarios used for the WMO insfrastructure requirements.</p>
          <label class="expand" for="uc1"></label>
          <input id="uc1" type="checkbox">
          <div>
          <p>This is really one of several future, but realistic, meteorological scenarios to aim at.</p>
          <p>National Hydro-Meteorological Services around the world are coordinated via the WMO (World Meteorological Organisation), part of the the United Nations system. WMO has the same status as ISO, and its standards and regulatory materials applies to all its 193 national meteorological services and are available in the six working languages ( عربي | 中文 | Fr | Ru | Es | En). WMO has embarked on a long-term (think a decade or so) programme to update the global meteorological operational infrastructure. This is known as the WIS (WMO Information System). The global infrastructure also has aviation, oceanographic, seismic and other users. The WIS includes a global, federated, synchronized, geospatial catalogue, envisaged to encompass all hydro-meteorological data and services. Currently several nodes are operational, cataloguing mainly routinely exchanged observations and forecasts.</p>
          <p>Envisage an environmental scientist in Cambodia, researching the impact of deforestation in Vietnam as part of investigating the regional impacts of climate change. She submits her search keywords, in Cambodian, and receives responses indicating there is some data from the 1950s, printed in a 1960 pamphlet, in the Bibliothèque Nationale, a library in Paris, France, in French. She receives an abstract of some form that enables her to decide that the data are worth accessing, and initiates a request for a digital copy to be sent.</p>
          <p>She receives the pamphlet as a scanned image of each page, and she decides that the quantatitive information in the paper is useful, so she arranges transcription of the tabular numerical data and their summary values into a digital form and publishes the dataset, with a persistent identifier, and links it to a detailed coverage extent, the original paper source, the scanned pages and her paper when it is published. She also incorporates scanned charts and graphs from the orginal pamphlet into her paper.Her organisation creates a catalogue record for her research paper dataset and publishes it in the WIS global catalogue, which makes it also visible to the GEO System of Systems broker portal.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SemanticSensorNetworkVocabulary"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"><a href="#Discoverability"></a></p>
        </section>
        <section id="HabitatZoneVerification">
          <h3>Habitat zone verification for designation of Marine Conservation Zones</h3>
          <p class="contributor">Jeremy Tandy</p>
          <label class="expand" for="uc2"></label>
          <input id="uc2" type="checkbox">
          <div>
            <p>The <a href="http://jncc.defra.gov.uk/page-5230">Marine and Coastal Access Act 2009</a> allows for the creation of a type of Marine Protected Area (MPA), called a Marine Conservation Zone (MCZ). MCZs protect a range of nationally important marine wildlife, habitats, geology and geomorphology and can be designated anywhere in English and Welsh inshore and UK offshore waters.</p>
            <p>The designation of a MCZ is dependent on a detailed analysis of the marine environment which results in the definition of geometric areas where a given habitat type is deemed to occur and is published as a habitat map.</p>
            <p>Being a policy statement, it is important to be able to express the provenance of information that was used to compile the habitat map. Moreover, because the marine environment is always changing, it is important to express the time at which this information was collected.</p>
            <p>The information includes:
            <ul>
              <li>acoustic survey</li>
              <li>video (from a video camera towed behind a boat)</li>
              <li>biota observations (based on what is observed in the video and physical collection)</li>
              <li>particle size (sand/mud)</li>
              <li>water column data</li>
              <li>seabed character map: discrete seabed features & backscatter information (from sonar) to determine bottom type</li>
            </ul>
            These information types are varied in type and size. In particular, the acoustic survey (e.g. side-scan sonar) is difficult to manage as these survey results can be many gigabytes in size and cover large areas. A way is needed to refer to just a small part of these coverage data sets that are relevant to a particular habitat zone analysis.
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SemanticSensorNetworkVocabulary"></a>, <a href="#CoverageInLinkedData"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="RealtimeWildfireMonitoring">
          <h3>Real-time Wildfire Monitoring</h3>
          <p class="contributor">Manolis Koubarakis</p>
          <label class="expand" for="uc3"></label>
          <input id="uc3" type="checkbox">
          <div>
            <p>This use case is about the wildfire monitoring service of the National Observatory of Athens (NOA) as studied in project <a href ="http://www.earthobservatory.eu/">TELEIOS</a>.The wildfire monitoring service is based on the use of satellite images originating from the SEVIRI (Spinning Enhanced Visible and Infrared Imager) sensor on top of the Meteosat Second Generation satellites MSG-1 and MSG-2. Since 2007, NOA operates an MSG/SEVIRI acquisition station, and has been systematically archiving raw satellite images on a 5 and 15 minutes basis, the respective temporal resolutions of MSG-1 and MSG-2.</p>
            <p>The service active in NOA before TELEIOS can be summarized as follows:
            <ol>
              <li> The ground-based receiving antenna collects all spectral bands from MSG-1 and MSG-2 every 5 and 15 minutes respectively.</li>
              <li>The raw datasets are decoded and temporarily stored in the METEOSAT Ground Station as wavelet compressed images.</li>
              <li>A Python program manages the data stream in real-time by offering the following functionality:
              <ol>
                <li>Extract and store the raw file metadata in an SQLite database. This metadata describes the type of sensor, the acquisition time, the spectral bands captured, and other related parameters. Such a step is required as one image comprises multiple raw files, which might arrive out-of-order.</li>
                <li>Filter the raw data files, disregarding non-applicable data for the fire monitoring scenario, and dispatch them to a dedicated disk array for permanent storage.</li>
                <li>Trigger the processing chain by transferring the appropriate spectral bands via FTP to a dedicated machine and initiating the following steps: (i) cropping the image to keep only the area of interest, (ii) georeferencing to the geodetic reference system used in Greece (HGRS 87), (iii) classifying the image pixels as "fire" or "non-fire" using appropriate algorithms, and finally (iv) exporting the final product to raster and vector formats (ESRI shapefiles).</li>
                <li>Dispatch the derived products to the disk array and additionally store them in a PostGIS database system.</li>
              </ol></li>
            </ol>
            It would be interesting for NOA to see how to use the standards developed by this working group to achieve the following:
            <ul>
            <li>Improve the thematic accuracy of generated products.</li>
            <li>Generate thematic maps by combining the generated products with other kinds of data such as: Corine Land Cover, the Administrative Geography of Greece, OpenStreetMap data and Geonames.</li>
            </ul>
            This use case is further discussed in <a href="http://cgi.di.uoa.gr/~koubarak/publications/edbt2013.pdf">this paper</a>.<br>
            The service is operational <a href = "http://ocean.space.noa.gr/seviri_u/fend_new/index.php">here</a>.<br>
            Some data that can be used by the service can be found <a href="http://linkedopendata.gr/">here</a>.
            </p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SemanticSensorNetworkVocabulary"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="DiachronicBurntScarMapping">
          <h3>Diachronic Burnt Scar Mapping</h3>
          <p class="contributor">Manolis Koubarakis</p>
          <label class="expand" for="uc4"></label>
          <input id="uc4" type="checkbox">
          <div>
          <p>This use case was studied by the National Observatory of Athens (NOA) in project <a href ="http://www.earthobservatory.eu/">TELEIOS</a>. The burnt scar mapping service is dedicated to the accurate mapping of burnt areas in Greece after the end of the summer fire seasons, using Landsat 5 TM satellite images. The processing chain of this service is divided into three stages, each one containing a series of modules.</p>
          <p>The pre-processing stage is dedicated to (i) identification of appropriate data, downloading and archiving, (ii) georeferencing of the received satellite images, and (iii) cloud masking process to exclude pixels “contaminated” by clouds from the subsequent processing steps.</p>
          <p>The core processing stage comprises (i) a classification algorithm which identifies burnt and non-burnt sets of pixels, (ii) a noise removal process that is necessary to eliminate isolated pixels that have been classified wrongfully as burnt, and (ii) converting the raster intermediate product to vector format.</p>
          <p>Finally, the post-processing stage consists of (i) a visual refinement step to ensure product thematic accuracy and consistency, (ii) attribute enrichment of the product by overlaying the polygons with geoinformation layers and finally (iii) generation of thematic maps.It would be interesting for NOA to see where the standards to be developed in this working group could be used.</p>
          <p>The service is operational <a href="http://ocean.space.noa.gr/seviri_u/fend_new/index.php">here</a>.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a>, <a href="#TimeOntologyInOWL"></a>, <a href="#SemanticSensorNetworkVocabulary"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="HarvestingLocalSearchContent">
          <h3>Harvesting of Local Search Content</h3>
          <p class="contributor">Ed Parsons</p>
          <label class="expand" for="uc5"></label>
          <input id="uc5" type="checkbox">
          <div>
          <p>This is a rather generic and broad use case, relevant to Google but clearly also relevant to anyone interesting in machine processing of html referring to about locations and activities which take place at those locations. Local search providers spend much time and effort creating databases of local facilities, businesses and events.</p>
          <p>Much of this information comes from web pages published on the public web, but in an unstructured form. Previous attempts at harvesting this information automatically have meet with only limited success, currently alternative approaches involve business owners manually adding structured data to dedicated portals. This approach although clearly an improvement does not really scale and there are clearly issues in terms of data sharing and freshness.</p>
          <p>The information of interest includes:
          <ul>
          <li>The facilities address</li>
          <li>The type of business/activity</li>
          <li>Opening hours</li>
          <li>Date, time and duration duration of events</li>
          <li>Telephone, e-mail and website details</li>
          </ul>
          </p>
          <p>Complexities to this include multiple address standards, the differences between qualitative representations of place, and precise spatial co-ordinates, definitions of activities etc.</p>
          <p>Ultimately these web pages should become the canonical source of local data used by all web users and services.</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
        <section id="LocatingAThing">
          <h3>Locating a thing</h3>
          <p class="contributor">Ed Parsons</p>
          <label class="expand" for="uc6"></label>
          <input id="uc6" type="checkbox">
          <div>
          <p>With the increasing availability of small, mobile location aware devices the requirement to identify a location human terms is becoming more important. While the determination of sensor in space to a high level of precision is a largely solved problem we are less able to express the location in terms meaningful to humans. The fact that the Bluetooth-LE tracker attached to my bag is at 51.4256853,-0.3317991,4.234500 is much less useful than the description, "Under your bed at home". At others times the location descriptions "24 Bridgeman Road, Teddington, TW11 8AH, UK" might be equally valid, as might "Teddington", "South West London", "England", "UK", "Inside", "Where you left it Yesterday", "Upstairs", "45 minutes from here" or "150 metres from the Post Office".</p>
          <p>A better understanding of how we describe places in human terms, the hierarchical nature of places and the fuzzy nature of many geographical entities will be needed to make the "Internet of Things" manageable. A new scale of geospatial analysis may be required using a reference frame based on the locations of individuals rather than a global spherical co-ordinate, allowing a location of your keys and their attached bluetooth tag to be described as "in the kitchen".</p>
          </div>
          <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
          <p class="relatedRequirements"></p>
        </section>
    </section>
    <section>
      <h2>Requirements</h2>
      <p>This chapter lists the requirements for the deliverables of the Working Group.</p>
      <!-- Template for requirments:
       <section id="Discoverability">
        <h3></h3>
        <p>I</p>
        <p class="relatedDeliverables"></a></p>
        <p class="relatedUseCases"></a></p>
      </section>
      -->
      <section id="Discoverability">
        <h3>Discoverability</h3>
        <p>It should be easy to find spatial data on the web.</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"><a href="#MeteorologicalDataRescue"></a></p>
      </section>
      <section id="SpatialMetadata">
        <h3>Spatial metadata</h3>
        <p>There should be standards that allow data sources (data sets or data services) to describe their spatial characteristics (like number of dimensions, data type (raster or vector), CRSs, spatial extent, spatial resolution)</p>
        <p class="relatedDeliverables"><a href="#BestPractices"></a></p>
        <p class="relatedUseCases"></a></p>
      </section>
    </section>
  </body>

